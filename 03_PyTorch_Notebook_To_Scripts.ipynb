{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6jdYhvK3/8uCy0dqavTnh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VesalAhsani/Deep-learning-with-PyTorch/blob/main/03_PyTorch_Notebook_To_Scripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructor: Dr. Vesal Ahsani\n",
        "\n",
        "This section answers the question\n",
        "\n",
        "**\"how do I turn my notebook code (Jupyter Notebook or Google Colab Notebook) into Python scripts?\"**"
      ],
      "metadata": {
        "id": "EQdu2mig2jRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is script mode?\n",
        "\n",
        "**Script mode** uses [Jupyter Notebook cell magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) (special commands) to turn specific cells into Python scripts.\n",
        "\n",
        "For example if you run the following code in a cell, you'll create a Python file called `hello_world.py`:\n",
        "\n",
        "```\n",
        "%%writefile hello_world.py\n",
        "print(\"hello world, machine learning is fun!\")\n",
        "```\n",
        "\n",
        "You could then run this Python file on the command line with:\n",
        "\n",
        "```\n",
        "python hello_world.py\n",
        "\n",
        ">>> hello world, machine learning is fun!\n",
        "```\n",
        "\n",
        "The main cell magic we're interested in using is `%%writefile`.\n",
        "\n",
        "Putting `%%writefile filename` at the top of a cell in Jupyter or Google Colab will write the contents of that cell to a specified `filename`.\n"
      ],
      "metadata": {
        "id": "gp-UZRHhTwbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "As an example, if you find a PyTorch project on GitHub, it may be structured in the following way:\n",
        "\n",
        "```\n",
        "pytorch_project/\n",
        "├── pytorch_project/\n",
        "│   ├── data_setup.py\n",
        "│   ├── engine.py\n",
        "│   ├── model.py\n",
        "│   ├── train.py\n",
        "│   └── utils.py\n",
        "├── models/\n",
        "│   ├── model_1.pth\n",
        "│   └── model_2.pth\n",
        "└── data/\n",
        "    ├── data_folder_1/\n",
        "    └── data_folder_2/\n",
        "```\n",
        "\n",
        "Here, the top level directory is called `pytorch_project` but you could call it whatever you want.\n",
        "\n",
        "Inside there's another directory called `pytorch_project` which contains several `.py` files, the purposes of these may be:\n",
        "* `data_setup.py` - a file to prepare data (and download data if needed).\n",
        "* `engine.py` - a file containing various training functions.\n",
        "* `model_builder.py` or `model.py` - a file to create a PyTorch model.\n",
        "* `train.py` - a file to leverage all other files and train a target PyTorch model.\n",
        "* `utils.py` - a file dedicated to helpful utility functions.\n",
        "\n",
        "And the `models` and `data` directories could hold PyTorch models and data files respectively (though due to the size of models and data files, it's unlikely you'll find the *full* versions of these on GitHub, these directories are present above mainly for demonstration purposes).\n",
        "\n",
        "> **Note:** There are many different ways to structure a Python project and subsequently a PyTorch project. This isn't a guide on *how* to structure your projects, only an example of how you *might* come across PyTorch projects."
      ],
      "metadata": {
        "id": "tmWnTqqFSeX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get the data"
      ],
      "metadata": {
        "id": "MT2GhqWJjSpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "r7fbmWiEhDtQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = Path(\"data/\")\n",
        "data_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(\"data/food101_pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/VesalAhsani/Deep-learning-with-PyTorch/raw/main/data/food101_pizza_steak_sushi.zip\")\n",
        "  f.write(request.content)"
      ],
      "metadata": {
        "id": "yKcJAYg2Q-3g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"data/food101_pizza_steak_sushi.zip\", \"r\") as zz:\n",
        "  zz.extractall(\"data/food101_pizza_steak_sushi\")"
      ],
      "metadata": {
        "id": "h0FAVAyvh1k6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create datasets and dataloaders\n",
        "\n",
        "data -> ImageFolder -> DataLoader"
      ],
      "metadata": {
        "id": "n64TsY67juS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_folder = Path(\"food101_project\").mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "wWBnzJ6Ooi6k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile food101_project/data_setup.py\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_transform = transforms.Compose([transforms.Resize(size=(64,64)),\n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "train_dir = \"data/food101_pizza_steak_sushi/train\"\n",
        "test_dir = \"data/food101_pizza_steak_sushi/test\"\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir,\n",
        "                                     transform=data_transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir,\n",
        "                                    transform=data_transform)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "BATCH_SIZE=32\n",
        "NUM_WORKERS = 1\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True,\n",
        "                              num_workers=NUM_WORKERS)\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=False,\n",
        "                              num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMqxxB4pjFTv",
        "outputId": "c5c6a357-7cef-46dd-8883-f83909c8b19a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting food101_project/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Making a model"
      ],
      "metadata": {
        "id": "Ah5spHYMpfpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile food101_project/model_builder.py\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Food101Model(nn.Module):\n",
        "  def __init__(self, input_shape, hidden_units, output_shape):\n",
        "    super().__init__()\n",
        "\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features= 1690,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.classifier(self.block_2(self.block_1(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27bFPlZRnZNr",
        "outputId": "322e509b-3b40-4251-e37e-ea6f31b00ff3"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting food101_project/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create functions for training and testing loops"
      ],
      "metadata": {
        "id": "e5Pg6m-fsKuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile food101_project/engine.py\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "def train_step(model, dataloader, loss_fn, accuracy_fn, optimizer, device):\n",
        "  \n",
        "  model.train()\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model, dataloader, loss_fn, accuracy_fn, device):\n",
        "  \n",
        "  model.eval()\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch , (X,y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      test_pred = model(X)\n",
        "      loss = loss_fn(test_pred, y)\n",
        "      test_loss += loss\n",
        "      test_acc += accuracy_fn(test_pred, y)\n",
        "  \n",
        "    test_loss /= len(dataloader)\n",
        "    test_acc /= len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "\n",
        "results = {\"train_loss\": [],\n",
        "           \"train_acc\": [],\n",
        "           \"test_loss\": [],\n",
        "           \"test_acc\": []\n",
        "}\n",
        "\n",
        "def train(model, train_dataloader, test_dataloader, loss_fn, accuracy_fn, optimizer, epochs, device):\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader=train_dataloader,\n",
        "                                       loss_fn=loss_fn,\n",
        "                                       accuracy_fn = accuracy_fn,\n",
        "                                       optimizer=optimizer,\n",
        "                                       device=device)\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                       dataloader=test_dataloader,\n",
        "                                       loss_fn=loss_fn,\n",
        "                                       accuracy_fn = accuracy_fn,\n",
        "                                       device=device)\n",
        "    \n",
        "    print(f\"Epochs: {epoch+1} | train_loss: {train_loss} | train_acc: {train_acc} | test_loss: {test_loss} | test_acc: {test_acc}\")\n",
        "\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_loss)\n",
        "    results[\"test_loss\"].append(train_loss)\n",
        "    results[\"test_acc\"].append(train_loss)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX3Zlz_jrN_H",
        "outputId": "b2a4bec5-3d6a-4ba5-d3ae-0f387549f719"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting food101_project/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Save a model"
      ],
      "metadata": {
        "id": "GQYts90_zfew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile food101_project/utils.py\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save(model, save_path):\n",
        "  \"\"\"\n",
        "  save_path should include .pth or .pt at the end.\n",
        "  \"\"\"  \n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ24h6nPyrhY",
        "outputId": "08fc8349-51b4-449a-932c-fb9e0409749b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting food101_project/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Train, evaluate and save the model, All together\n",
        "\n",
        "Let's combine all of our modular files into a single script `train.py`.\n",
        "\n",
        "This will allow us to run all of the functions we've written with a single line of code on the command line:\n",
        "\n",
        "`python food101_pizza_steak_sushi/train.py`\n",
        "\n",
        "Or if we're running it in a notebook:\n",
        "\n",
        "`!python food101_pizza_steak_sushi/train.py`\n",
        "\n",
        "We'll go through the following steps:\n",
        "1. Import the various dependencies, namely `torch`, `os`, `torchvision.transforms` and all of the scripts from the `food101_pizza_steak_sushi` directory, `data_setup`, `engine`, `model_builder`, `utils`.\n",
        "  * **Note:** Since `train.py` will be *inside* the `food101_pizza_steak_sushi` directory, we can import the other modules via `import ...` rather than `from food101_pizza_steak_sushi import ...`.\n",
        "2. Setup various hyperparameters such as batch size, number of epochs, learning rate and number of hidden units (these could be set in the future via [Python's `argparse`](https://docs.python.org/3/library/argparse.html)).\n",
        "3. Setup the training and test directories.\n",
        "4. Setup device-agnostic code.\n",
        "5. Create the necessary data transforms.\n",
        "6. Create the DataLoaders using `data_setup.py`.\n",
        "7. Create the model using `model_builder.py`.\n",
        "8. Setup the loss function and optimizer.\n",
        "9. Train the model using `engine.py`.\n",
        "10. Save the model using `utils.py`. "
      ],
      "metadata": {
        "id": "vZT8txSb3q8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile food101_project/train.py\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torchmetrics\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "import data_setup, engine, model_builder, utils\n",
        "\n",
        "# Setup hyperparameters\n",
        "BATCH_SIZE=32\n",
        "NUM_WORKERS = 1\n",
        "NUM_EPOCHS = 20\n",
        "HIDDEN_UNITS=10\n",
        "LEARNING_RATE=0.001\n",
        "\n",
        "# Setup directories\n",
        "train_dir = \"data/food101_pizza_steak_sushi/train\"\n",
        "test_dir = \"data/food101_pizza_steak_sushi/test\"\n",
        "\n",
        "# setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Pipeline\n",
        "\n",
        "\n",
        "model_0 = model_builder.Food101Model(input_shape=3, \n",
        "                                     hidden_units=HIDDEN_UNITS, \n",
        "                                     output_shape=len(data_setup.class_names)\n",
        "                                     ).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
        "                             lr=LEARNING_RATE)\n",
        "accuracy_fn = Accuracy().to(device)\n",
        "\n",
        "engine.train(model=model_0,\n",
        "             train_dataloader=data_setup.train_dataloader,\n",
        "             test_dataloader=data_setup.test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             optimizer=optimizer,\n",
        "             epochs=NUM_EPOCHS,\n",
        "             device=device\n",
        "             )\n",
        "\n",
        "utils.save(model=model_0,\n",
        "           save_path = \"model/01_scrip_version_food101_sample.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aACAROhb2kuG",
        "outputId": "9602b05f-131a-4a00-ad5c-43b1d2b4d82f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting food101_project/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python food101_project/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_kxj29A_ybN",
        "outputId": "0796e21f-ba8e-4e80-f671-e3e2204cf41d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0% 0/20 [00:00<?, ?it/s]Epochs: 1 | train_loss: 1.1005330085754395 | train_acc: 0.27734375 | test_loss: 1.1083883047103882 | test_acc: 0.2708333432674408\n",
            "  5% 1/20 [00:02<00:42,  2.24s/it]Epochs: 2 | train_loss: 1.1059037446975708 | train_acc: 0.3125 | test_loss: 1.120385766029358 | test_acc: 0.1979166716337204\n",
            " 10% 2/20 [00:04<00:40,  2.22s/it]Epochs: 3 | train_loss: 1.0856938362121582 | train_acc: 0.42578125 | test_loss: 1.0861849784851074 | test_acc: 0.4422348439693451\n",
            " 15% 3/20 [00:06<00:37,  2.21s/it]Epochs: 4 | train_loss: 1.068902611732483 | train_acc: 0.44140625 | test_loss: 1.046971321105957 | test_acc: 0.5227272510528564\n",
            " 20% 4/20 [00:08<00:35,  2.20s/it]Epochs: 5 | train_loss: 1.0447355508804321 | train_acc: 0.390625 | test_loss: 0.9936234354972839 | test_acc: 0.5539772510528564\n",
            " 25% 5/20 [00:11<00:33,  2.21s/it]Epochs: 6 | train_loss: 0.9125605821609497 | train_acc: 0.59375 | test_loss: 1.0024447441101074 | test_acc: 0.38257575035095215\n",
            " 30% 6/20 [00:13<00:31,  2.22s/it]Epochs: 7 | train_loss: 0.8116193413734436 | train_acc: 0.62890625 | test_loss: 1.0368106365203857 | test_acc: 0.35132575035095215\n",
            " 35% 7/20 [00:15<00:28,  2.21s/it]Epochs: 8 | train_loss: 0.7502362132072449 | train_acc: 0.62109375 | test_loss: 1.005202293395996 | test_acc: 0.4232954680919647\n",
            " 40% 8/20 [00:17<00:26,  2.21s/it]Epochs: 9 | train_loss: 0.7950915694236755 | train_acc: 0.6640625 | test_loss: 0.9895709156990051 | test_acc: 0.4232954680919647\n",
            " 45% 9/20 [00:19<00:24,  2.20s/it]Epochs: 10 | train_loss: 0.767094612121582 | train_acc: 0.65234375 | test_loss: 1.0194106101989746 | test_acc: 0.4024621248245239\n",
            " 50% 10/20 [00:22<00:22,  2.21s/it]Epochs: 11 | train_loss: 0.8588557839393616 | train_acc: 0.52734375 | test_loss: 0.929996907711029 | test_acc: 0.4744318425655365\n",
            " 55% 11/20 [00:24<00:19,  2.21s/it]Epochs: 12 | train_loss: 0.7113381624221802 | train_acc: 0.65234375 | test_loss: 0.9033817648887634 | test_acc: 0.625\n",
            " 60% 12/20 [00:26<00:17,  2.21s/it]Epochs: 13 | train_loss: 0.7639275789260864 | train_acc: 0.6953125 | test_loss: 0.9880752563476562 | test_acc: 0.4232954680919647\n",
            " 65% 13/20 [00:28<00:15,  2.22s/it]Epochs: 14 | train_loss: 0.7482665181159973 | train_acc: 0.671875 | test_loss: 1.043533205986023 | test_acc: 0.41287878155708313\n",
            " 70% 14/20 [00:31<00:13,  2.22s/it]Epochs: 15 | train_loss: 0.7116259336471558 | train_acc: 0.7421875 | test_loss: 0.9940316677093506 | test_acc: 0.4545454680919647\n",
            " 75% 15/20 [00:33<00:11,  2.23s/it]Epochs: 16 | train_loss: 0.6748617887496948 | train_acc: 0.74609375 | test_loss: 1.069825530052185 | test_acc: 0.40340909361839294\n",
            " 80% 16/20 [00:35<00:08,  2.23s/it]Epochs: 17 | train_loss: 0.6970038414001465 | train_acc: 0.6953125 | test_loss: 1.0775913000106812 | test_acc: 0.3636363744735718\n",
            " 85% 17/20 [00:37<00:06,  2.22s/it]Epochs: 18 | train_loss: 0.6336610913276672 | train_acc: 0.7109375 | test_loss: 0.9981606602668762 | test_acc: 0.43465909361839294\n",
            " 90% 18/20 [00:39<00:04,  2.22s/it]Epochs: 19 | train_loss: 0.627015233039856 | train_acc: 0.76953125 | test_loss: 1.0618122816085815 | test_acc: 0.43560609221458435\n",
            " 95% 19/20 [00:42<00:02,  2.23s/it]Epochs: 20 | train_loss: 0.7279651761054993 | train_acc: 0.609375 | test_loss: 1.0673326253890991 | test_acc: 0.44507575035095215\n",
            "100% 20/20 [00:44<00:00,  2.22s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that we could train our model by `python train.py` in the command line or `!python train.py` in cell."
      ],
      "metadata": {
        "id": "jQ77Lcy-IR2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And if we wanted to, we could adjust our `train.py` file to use argument flag inputs with Python's argparse module, this would allow us to provide different hyperparameter settings like previously discussed:\n",
        "\n",
        "`python train.py --model MODEL_NAME --batch_size BATCH_SIZE --lr LEARNING_RATE --num_epochs NUM_EPOCHS`\n",
        "\n"
      ],
      "metadata": {
        "id": "0aWBmZsUIsI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "we should import required libararies in each of the `.py` files when we write our code. In other words, importing all packages in the `train.py` file is not enough!"
      ],
      "metadata": {
        "id": "CNlYPHB2I6SX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BTW, our model results are not satisfactory. We should work on it later to improve!"
      ],
      "metadata": {
        "id": "CLoL1RGsJhgi"
      }
    }
  ]
}