{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VesalAhsani/Deep-learning-with-PyTorch/blob/main/07_PyTorch_Model_Deployment_Huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17fY9laXddNW"
      },
      "source": [
        "## Instructor: Dr. Vesal Ahsani\n",
        "\n",
        "## PyTorch Model Deployment\n",
        "\n",
        "\n",
        "*we're going to deploy our FoodVision model to the internet as a usable app!*\n",
        "\n",
        "\n",
        "## What is machine learning model deployment?\n",
        "\n",
        "**Machine learning model deployment** is the process of making your machine learning model accessible to someone or something else.\n",
        "\n",
        "Someone else being a person who can interact with your model in some way. \n",
        "\n",
        "For example, someone taking a photo on their smartphone of food and then having our FoodVision Mini model classify it into pizza, steak or sushi.\n",
        "\n",
        "Something else might be another program, app or even another model that interacts with your machine learning model(s). \n",
        "\n",
        "For example, a banking database might rely on a machine learning model making predictions as to whether a transaction is fraudulent or not before transferring funds.\n",
        "\n",
        "Or an operating system may lower its resource consumption based on a machine learning model making predictions on how much power someone generally uses at specific times of day.\n",
        "\n",
        "These use cases can be mixed and matched as well.\n",
        "\n",
        "For example, a Tesla car's computer vision system will interact with the car's route planning program (something else) and then the route planning program will get inputs and feedback from the driver (someone else).\n",
        "\n",
        "          \n",
        "          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FN2LpGyddNf"
      },
      "source": [
        "\n",
        "what happens if someone was to upload a photo that *wasn't* of food to our FoodVision model?\n",
        "\n",
        "One solution would be to create another model that first classifies images as \"food\" or \"not food\" and passing the target image through that model first.\n",
        "\n",
        "Then if the image is of \"food\" it goes to our FoodVision model.\n",
        "\n",
        "And if it's \"not food\", a message is displayed.\n",
        "\n",
        "But what if these predictions were wrong?\n",
        "\n",
        "What happens then?\n",
        "\n",
        "You can see how these questions could keep going.\n",
        "\n",
        "Thus this highlights the importance of model deployment: it helps you figure out errors in your model that aren't obvious during training/testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdBG0eBoddNq"
      },
      "source": [
        "## Different types of machine learning model deployment\n",
        "\n",
        "\n",
        "1. **Where's it going to go?** - As in, where is it going to be stored?\n",
        "2. **How's it going to function?** - As in, does it return predictions immediately? Or do they come later?\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-deployment-questions-to-ask.png\" alt=\"some questions to ask when starting to deploy machine learning models, what's the model ideal use case, then work backwards and ask where's my model going to go and how's my model going to function\" width=900/>\n",
        "\n",
        "*When starting to deploy machine learning models, it's helpful to start by asking what's the most ideal use case and then work backwards from there, asking where the model's going to go and then how it's going to function.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "dKyxOIModdN0"
      },
      "source": [
        "### Where's it going to go?\n",
        "\n",
        "When you deploy your machine learning model, where does it live?\n",
        "\n",
        "The main debate here is usually on-device (also called edge/in the browser) or on the cloud (a computer/server that isn't the *actual* device someone/something calls the model from). \n",
        "\n",
        "Both have their pros and cons.\n",
        "\n",
        "| **Deployment location** | **Pros** | **Cons** | \n",
        "| ----- | ----- | ----- |\n",
        "| **On-device (edge/In the browser)** | Can be very fast (since no data leaves the device) | Limited compute power (larger models take longer to run) | \n",
        "| | Privacy preserving (again no data has to leave the device) | Limited storage space (smaller model size required) | \n",
        "| | No internet connection required (sometimes) | Device-specific skills often required | \n",
        "| | | | \n",
        "| **On cloud** | Near unlimited compute power (can scale up when needed) | Costs can get out of hand (if proper scaling limits aren't enforced) |\n",
        "| | Can deploy one model and use everywhere (via API) | Predictions can be slower due to data having to leave device and predictions having to come back (network latency) |\n",
        "| | Links into existing cloud ecosystem | Data has to leave device (this may cause privacy concerns) |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-model-deployment-on-device-vs-cloud.png\" width=900 alt=\"tesla computer vision system on device vs on the cloud\"/>\n",
        "\n",
        "*In the case of a Tesla car's computer vision system, which would be better? A smaller model that performs well on device (model is on the car) or a larger model that performs better that's on the cloud? In this case, you'd much prefer the model being on the car. The extra network time it would take for data to go from the car to the cloud and then back to the car just wouldn't be worth it (or potentially even possible with poor signal areas).*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06nxXaRVddOC"
      },
      "source": [
        "### How's it going to function?\n",
        "\n",
        "\n",
        "These two scenarios are generally referred to as:\n",
        "\n",
        "* **Online (real-time)** - Predicitions/inference happen **immediately**. For example, someone uploads an image, the image gets transformed and predictions are returned or someone makes a purchase and the transaction is verified to be non-fradulent by a model so the purchase can go through.\n",
        "\n",
        "> **Note:** Real-time in this case being ~30FPS (frames per second) because that's [about how fast the human eye can see](https://www.healthline.com/health/human-eye-fps) (there is debate on this but let's just use ~30FPS as our benchmark) (0.03 seconds inference time per image, also known as latency).\n",
        "\n",
        "* **Offline (batch)** - Predictions/inference happen **periodically**. For example, a photos application sorts your images into different categories (such as beach, mealtime, family, friends) whilst your mobile device is plugged into charge.\n",
        "\n",
        "> **Note:** \"Batch\" refers to inference being performed on multiple samples at a time. However, batch processing can happen immediately/online (multiple images being classified at once) and/or offline (mutliple images being predicted/trained on at once).  \n",
        "\n",
        "The main difference between each being: predictions being made immediately or periodically.\n",
        "\n",
        "\n",
        "In our case, we'd want our inference pipeline to happen online (real-time), so when someone uploads an image of food, the prediction results are returned immediately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSJ0z7-PddOE"
      },
      "source": [
        "### Ways to deploy a machine learning model\n",
        "\n",
        "We've discussed a couple of options for deploying machine learning models (on-device and cloud).\n",
        "\n",
        "And each of these will have their specific requirements:\n",
        "\n",
        "| **Tool/resource** | **Deployment type** | \n",
        "| ----- | ----- |\n",
        "| [Google's ML Kit](https://developers.google.com/ml-kit) | On-device (Android and iOS) | \n",
        "| [Apple's Core ML](https://developer.apple.com/documentation/coreml) and [`coremltools` Python package](https://coremltools.readme.io/docs) | On-device (all Apple devices) | \n",
        "| [Amazon Web Service's (AWS) Sagemaker](https://aws.amazon.com/sagemaker/) | Cloud | \n",
        "| [Google Cloud's Vertex AI](https://cloud.google.com/vertex-ai) | Cloud |\n",
        "| [Microsoft's Azure Machine Learning](https://azure.microsoft.com/en-au/services/machine-learning/) | Cloud |\n",
        "| [Hugging Face Spaces](https://huggingface.co/spaces) | Cloud |\n",
        "| API with [FastAPI](https://fastapi.tiangolo.com) | Cloud/self-hosted server |\n",
        "| API with [TorchServe](https://pytorch.org/serve/) | Cloud/self-hosted server | \n",
        "| [ONNX (Open Neural Network Exchange)](https://onnx.ai/index.html) | Many/general |\n",
        "| Many more... |\n",
        "\n",
        "> **Note:** An [application programming interface (API)](https://en.wikipedia.org/wiki/API) is a way for two (or more) computer programs to interact with each other. For example, if your model was deployed as API, you would be able to write a program that could send data to it and then receive predictions back.\n",
        "\n",
        "Which option you choose will be highly dependent on what you're building/who you're working with.\n",
        "\n",
        "\n",
        "And one of the best ways to do so is by turning your machine learning model into a demo app with [Gradio](https://gradio.app) and then deploying it on Hugging Face Spaces.\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-tools-and-places-to-deploy-ml-models.png\" alt=\"tools and places to deploy machine learning models\" width=900/>\n",
        "\n",
        "*A handful of places and tools to host and deploy machine learning models.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Start !!!"
      ],
      "metadata": {
        "id": "fF_U97yFtium"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA6moDlVddOS"
      },
      "source": [
        "## 1. Getting data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "try:\n",
        "  import torchmetrics\n",
        "except:\n",
        "  print(\"torchmetrics is not installed ...\")\n",
        "  !pip -q install torchmetrics"
      ],
      "metadata": {
        "id": "bFK_jL2FbznS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a02315f-116e-42cd-de97-27d70ca66f10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torchmetrics is not installed ...\n",
            "\u001b[K     |████████████████████████████████| 529 kB 6.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_p8m71FrdSnF",
        "outputId": "bb7585d9-0426-44e4-a680-6a4e14e72c82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds():\n",
        "  torch.manual_seed(42)\n",
        "  torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "8uxjE04kf67F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's create random 20 percent of Food101 data train and test dataset in our desired format \n",
        "\n",
        "#### you only use this part if you want to train your model on some parts of your whole data"
      ],
      "metadata": {
        "id": "CmpSB12V3-q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "data_dir = Path(\"data\")\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "# Get random 20% of training images\n",
        "import random\n",
        "\n",
        "# Setup data paths\n",
        "data_path = data_dir / \"food-101\" / \"images\"\n",
        "\n",
        "# Change amount of data to get (e.g. 0.1 = random 10%, 0.2 = random 20%)\n",
        "amount_to_get = 0.2\n",
        "\n",
        "# Create function to separate a random amount of data\n",
        "def get_subset(image_path=data_path,\n",
        "               data_splits=[\"train\", \"test\"],\n",
        "               amount=0.2,\n",
        "               seed=42):\n",
        "    random.seed(42)\n",
        "    label_splits = {}\n",
        "    \n",
        "    # Get labels\n",
        "    for data_split in data_splits:\n",
        "        print(f\"[INFO] Creating image split for: {data_split}...\")\n",
        "        label_path = data_dir / \"food-101\" / \"meta\" / f\"{data_split}.txt\"\n",
        "        with open(label_path, \"r\") as f:\n",
        "            labels = [line.strip(\"\\n\") for line in f.readlines()] \n",
        "        \n",
        "        # Get random subset of target classes image ID's\n",
        "        number_to_sample = round(amount * len(labels))\n",
        "        print(f\"[INFO] Getting random subset of {number_to_sample} images for {data_split}...\")\n",
        "        sampled_images = random.sample(labels, k=number_to_sample)\n",
        "        \n",
        "        # Apply full paths\n",
        "        image_paths = [Path(str(image_path / sample_image) + \".jpg\") for sample_image in sampled_images]\n",
        "        label_splits[data_split] = image_paths\n",
        "    return label_splits\n",
        "        \n",
        "label_splits = get_subset(amount=amount_to_get)\n",
        "label_splits[\"train\"][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1GCxDjezj4n",
        "outputId": "25df38dd-fae1-475e-e316-cfc1f6e317fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Creating image split for: train...\n",
            "[INFO] Getting random subset of 15150 images for train...\n",
            "[INFO] Creating image split for: test...\n",
            "[INFO] Getting random subset of 5050 images for test...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('data/food-101/images/chicken_quesadilla/2670687.jpg'),\n",
              " PosixPath('data/food-101/images/beef_tartare/2507172.jpg'),\n",
              " PosixPath('data/food-101/images/greek_salad/1260996.jpg'),\n",
              " PosixPath('data/food-101/images/french_toast/3917826.jpg'),\n",
              " PosixPath('data/food-101/images/foie_gras/1035427.jpg'),\n",
              " PosixPath('data/food-101/images/clam_chowder/2402986.jpg'),\n",
              " PosixPath('data/food-101/images/cheese_plate/75029.jpg'),\n",
              " PosixPath('data/food-101/images/sushi/2019344.jpg'),\n",
              " PosixPath('data/food-101/images/ceviche/1648055.jpg'),\n",
              " PosixPath('data/food-101/images/panna_cotta/357026.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target directory path\n",
        "target_dir_name = f\"data/food101_{str(int(amount_to_get*100))}_percent\"\n",
        "print(f\"Creating directory: '{target_dir_name}'\")\n",
        "\n",
        "# Setup the directories\n",
        "target_dir = Path(target_dir_name)\n",
        "\n",
        "# Make the directories\n",
        "target_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcWXFgqM0yXe",
        "outputId": "03694251-8d92-4cfc-c05d-aa71bcad7a48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating directory: 'data/food101_20_percent'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "for image_split in label_splits.keys():\n",
        "    for image_path in label_splits[str(image_split)]:\n",
        "        dest_dir = target_dir / image_split / image_path.parent.stem / image_path.name\n",
        "        if not dest_dir.parent.is_dir():\n",
        "            dest_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"[INFO] Copying {image_path} to {dest_dir}...\")\n",
        "        shutil.copy2(image_path, dest_dir)"
      ],
      "metadata": {
        "id": "kGVkoZc51Xlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check lengths of directories\n",
        "def walk_through_dir(dir_path):\n",
        "  import os\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "    \n",
        "walk_through_dir(target_dir)"
      ],
      "metadata": {
        "id": "Laol2uO12eLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCAR5NkhddOX"
      },
      "source": [
        "## 2. FoodVision model deployment experiment outline\n",
        "\n",
        "The ideal deployed model performs well and fast. \n",
        "\n",
        "We'd like our model to perform as close to real-time as possible.\n",
        "\n",
        "\n",
        "To try and achieve these results, let's bring in our best performing models from the previous sections: \n",
        "\n",
        "1. **EffNetB2 feature extractor** (EffNetB2 for short) - originally created using [`torchvision.models.efficientnet_b2()`](https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b2.html#efficientnet-b2) with adjusted `classifier` layers.\n",
        "2. **ViT-B/16 feature extractor** (ViT for short) - originally created using [`torchvision.models.vit_b_16()`](https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_b_16.html#vit-b-16) with adjusted `head` layers.\n",
        "    * **Note** ViT-B/16 stands for \"Vision Transformer Base, patch size 16\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq-pWL7XddOX"
      },
      "source": [
        "## 3. Creating an EffNetB2 feature extractor\n",
        "\n",
        "\n",
        "1. Setup the pretrained weights as [`weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT`](https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b2.html#torchvision.models.EfficientNet_B2_Weights), where \"`DEFAULT`\" means \"best currently available\" (or could use `weights=\"DEFAULT\"`). \n",
        "2. Get the pretrained model image transforms from the weights with the `transforms()` method (we need these so we can convert our images into the same format as the pretrained EffNetB2 was trained on).\n",
        "3. Create a pretrained model instance by passing the weights to an instance of [`torchvision.models.efficientnet_b2`](https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b2.html#efficientnet-b2).\n",
        "4. Freeze the base layers in the model.\n",
        "5. Update the classifier head to suit our own data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n2cSKgbYddOn"
      },
      "outputs": [],
      "source": [
        "def create_effnetb2_model(num_classes, \n",
        "                          seed):  \n",
        "    \"\"\"Creates an EfficientNetB2 feature extractor model and transforms.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int, optional): number of classes in the classifier head. \n",
        "        seed (int, optional): random seed value. Defaults to 42.\n",
        "\n",
        "    Returns:\n",
        "        model (torch.nn.Module): EffNetB2 feature extractor model. \n",
        "        transforms (torchvision.transforms): EffNetB2 image transforms.\n",
        "    \"\"\"\n",
        "    # 1, 2, 3. Create EffNetB2 pretrained weights, transforms and model\n",
        "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "    effnetb2_transforms = weights.transforms()\n",
        "    effnetb2 = torchvision.models.efficientnet_b2(weights=weights)\n",
        "\n",
        "    # 4. Freeze all layers in base model\n",
        "    for param in effnetb2.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 5. Change classifier head with random seed for reproducibility\n",
        "    torch.manual_seed(seed)\n",
        "    effnetb2.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.3, inplace=True),\n",
        "        nn.Linear(in_features=1408, out_features=num_classes),\n",
        "    )\n",
        "    \n",
        "    return effnetb2, effnetb2_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oGVxmqyCddOs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "709a6846dfcc492f8e47fb4ad6e457a1",
            "e6e14a21e6424afaa3e386fde4255f4c",
            "84ba9a44053340aabb89b8d90fbe6dec",
            "8301450d882f4c0e9aa8239725c47152",
            "8eb4b750b6154e74aeaa6d9a926a4356",
            "19521d3676284c83818999591c4c66fd",
            "1f89828c17a844b18a30ad75f023d2f8",
            "5105a1bd374047ffa61b7ce6fded38b2",
            "3813be9fc8fb4f2ca191779b94a585dd",
            "f4ae5c80aa954ee7a6ec96bace12cb27",
            "77bcc2babd4e4f94b873b6e6a5b2a665"
          ]
        },
        "outputId": "2230f591-88af-478b-fb37-cef866e3d0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-bcdf34b7.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-bcdf34b7.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/35.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "709a6846dfcc492f8e47fb4ad6e457a1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "effnetb2, effnetb2_transforms = create_effnetb2_model(num_classes=101,\n",
        "                                                      seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "food101_effnetb2_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.TrivialAugmentWide(),\n",
        "    effnetb2_transforms,\n",
        "])"
      ],
      "metadata": {
        "id": "k_Cxyz-yrc6H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yqDQmnRddOt"
      },
      "source": [
        "###  Creating DataLoaders for EffNetB2 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the optimizer\n",
        "optimizer = torch.optim.Adam(params=effnetb2.parameters(), \n",
        "                              lr=1e-3)\n",
        "\n",
        "# Setup the loss function for multi-class classification\n",
        "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "accuracy_fn = Accuracy().to(device)\n",
        "\n",
        "from pathlib import Path\n",
        "data_dir = Path(\"data\")\n",
        "\n",
        "#### When you want to make use of random part of Food101 data (whole dataset)\n",
        "\n",
        "# train_dir = \"data/food101_20_percent/train\"\n",
        "# test_dir = \"data/food101_20_percent/test\"\n",
        "\n",
        "\n",
        "# train_dataset = datasets.ImageFolder(root=train_dir, transform=food101_effnetb2_transforms)\n",
        "# test_dataset = datasets.ImageFolder(root=test_dir, transform=food101_effnetb2_transforms)\n",
        "\n",
        "#### When you want to tain your model on all of the data\n",
        "train_dataset = datasets.Food101(root=data_dir, \n",
        "                                 split=\"train\", \n",
        "                                 transform=food101_effnetb2_transforms,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.Food101(root=data_dir, \n",
        "                                 split=\"test\", \n",
        "                                 transform=food101_effnetb2_transforms,\n",
        "                                 download=True)\n",
        "\n",
        "BATCH_SIZE=32\n",
        "NUM_WORKERS = 1\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                shuffle=True,\n",
        "                                num_workers=NUM_WORKERS)\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                shuffle=False,\n",
        "                                num_workers=NUM_WORKERS)\n",
        "\n",
        "def train_step(model, dataloader, loss_fn, accuracy_fn, optimizer, device):\n",
        "  model.train()\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model, dataloader, loss_fn, accuracy_fn, device):\n",
        "  model.eval()\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      test_pred = model(X)\n",
        "      loss = loss_fn(test_pred, y)\n",
        "      test_loss += loss\n",
        "      test_acc += accuracy_fn(test_pred, y)\n",
        "\n",
        "    test_loss /= len(dataloader)\n",
        "    test_acc /= len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "def train(model, train_dataloader, test_dataloader, loss_fn, accuracy_fn, optimizer, epochs, device):\n",
        "  from tqdm.auto import tqdm\n",
        "\n",
        "  results = {\"train_loss\":[],\n",
        "             \"train_acc\":[],\n",
        "             \"test_loss\":[],\n",
        "             \"test_acc\":[]\n",
        "             }\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model, train_dataloader, loss_fn, accuracy_fn, optimizer, device)\n",
        "    test_loss, test_acc = test_step(model, test_dataloader, loss_fn, accuracy_fn, device)\n",
        "  \n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1} | train_loss: {train_loss:.4f} train_acc: {train_acc:.2f}% | test_loss: {test_loss:.4f} test_acc: {test_acc:.2f}%\")\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "qGw3zO8ecVCX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "7d7baeb96d934c3f9a947537e224b006",
            "fc6c141309bf40ac8b994eb00781a4a3",
            "8a674293a66046159e78bf0dfeb138a9",
            "0168096c8119457697f756a00ec2b669",
            "2bcf3272802d46baa3d40a224cd317c6",
            "c521c54541ea463a8d9363a87b4a012e",
            "c784a3ae3f1740b0871701dc6478ddde",
            "426e49392cb8494cba238a2bd1cf2db3",
            "98a0fd8fecdf4d93af7da41b9e171b4b",
            "f25fa5392c1442f08f4c8d544c1ff0d6",
            "db3b5ae008324de08e365ef8f3b73c2a"
          ]
        },
        "outputId": "591e696c-bf9c-440d-f266-a081f61c62cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz to data/food-101.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4996278331 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d7baeb96d934c3f9a947537e224b006"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/food-101.tar.gz to data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n-L-BbtddOt"
      },
      "source": [
        "### Training EffNetB2 feature extractor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seeds()\n",
        "food101_results_effnetb2 = train(effnetb2.to(device),train_dataloader,test_dataloader,loss_fn,accuracy_fn,optimizer,5,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "c441a6838b7a4185b9d55c8066b816dd",
            "34d1c78ffd344d4781ad3009b20c41a1",
            "b53978f8b5cb4b58828b208441b7cf0c",
            "650a82d2f6d74c66b2de76bda1cd7123",
            "b3b127c2680a4f9396710790dd6d559d",
            "28682488e055400ebceda82ad4f554ac",
            "55941e543f244ceaa693f9b687a49982",
            "445b389bb1604f16b595250eea30d18e",
            "66be4353933448a689cb6c6ca4b201d0",
            "a4b5c84c25034c9f8ed5289bad4832f4",
            "b200aa5facfc4bcc97ca2c7f492382b2"
          ]
        },
        "id": "2rloK18rgHvd",
        "outputId": "c83a294e-ce1d-423f-db6c-f71c97a8c4a2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c441a6838b7a4185b9d55c8066b816dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 2.9841 train_acc: 0.41% | test_loss: 2.3764 test_acc: 0.55%\n",
            "Epoch: 2 | train_loss: 2.6495 train_acc: 0.48% | test_loss: 2.2870 test_acc: 0.57%\n",
            "Epoch: 3 | train_loss: 2.6161 train_acc: 0.49% | test_loss: 2.2633 test_acc: 0.58%\n",
            "Epoch: 4 | train_loss: 2.5940 train_acc: 0.50% | test_loss: 2.2419 test_acc: 0.59%\n",
            "Epoch: 5 | train_loss: 2.5908 train_acc: 0.50% | test_loss: 2.2313 test_acc: 0.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md-k6-4xddOu"
      },
      "source": [
        "### Inspecting EffNetB2 loss curves \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot loss curves\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "train_loss=[]\n",
        "train_acc=[]\n",
        "test_loss=[]\n",
        "test_acc=[]\n",
        "for i in range(len(food101_results_effnetb2[\"train_loss\"])):\n",
        "  tr_loss = food101_results_effnetb2[\"train_loss\"][i].cpu().detach().numpy().item()\n",
        "  tr_acc = food101_results_effnetb2[\"train_acc\"][i].cpu().detach().numpy().item()\n",
        "  te_loss = food101_results_effnetb2[\"test_loss\"][i].cpu().detach().numpy().item()\n",
        "  te_acc = food101_results_effnetb2[\"test_acc\"][i].cpu().detach().numpy().item()\n",
        "\n",
        "  train_loss.append(tr_loss)\n",
        "  train_acc.append(tr_acc)\n",
        "  test_loss.append(te_loss)\n",
        "  test_acc.append(te_acc)\n",
        "\n",
        "epochs = range(len(food101_results_effnetb2[\"train_loss\"]))\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, train_loss, label = \"train_loss\")\n",
        "plt.plot(epochs, test_loss, label = \"test_loss\")\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, train_acc, label = \"train_acc\")\n",
        "plt.plot(epochs, test_acc, label = \"test_acc\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Fer2jsbi_4K2",
        "outputId": "557dd70e-6be2-4485-da8d-77db548cc5b1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "86EmDjI_ddOv"
      },
      "source": [
        "### Saving EffNetB2 feature extractor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = Path(\"models\")\n",
        "model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "torch.save(obj=effnetb2.state_dict(),\n",
        "           f=\"models/food101_effnetb2_feature_extractor_101classes.pth\")"
      ],
      "metadata": {
        "id": "rAkrrH28-8CN"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Food101 compatible EffNetB2 instance\n",
        "loaded_effnetb2_food101, effnetb2_transforms = create_effnetb2_model(num_classes=101, seed=42)\n",
        "\n",
        "# Load the saved model's state_dict()\n",
        "loaded_effnetb2_food101.load_state_dict(torch.load(\"models/food101_effnetb2_feature_extractor_101classes.pth\", map_location=torch.device('cpu')))\n",
        "\n",
        "# loaded_effnetb2_food101.load_state_dict(torch.load(\"models/food101_effnetb2_feature_extractor_101classes.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gad6eWJzAr5Q",
        "outputId": "840a2221-fb5f-4e90-901f-5b29f5f11b97"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzy1WU-3ddOx"
      },
      "source": [
        "### Checking the size of EffNetB2 feature extractor\n",
        "\n",
        "To check our model's size in bytes, we can use Python's [`pathlib.Path.stat(\"path_to_model\").st_size`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat) and then we can convert it (roughly) to megabytes by dividing it by `(1024*1024)`. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "food101_effnetb2_size = Path(\"models/food101_effnetb2_feature_extractor_101classes.pth\").stat().st_size // 1024**2\n",
        "print(f\"The Food101 efficientNetB2 feature extractor model size is {food101_effnetb2_size} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwCIXC1bP-Qz",
        "outputId": "328f8ed6-4f20-4238-cf0e-c4ad1a80864a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Food101 efficientNetB2 feature extractor model size is 30 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f47ZPzH8ddOy"
      },
      "source": [
        "### Collecting EffNetB2 feature extractor stats\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_stats = {\n",
        "    \"test_loss\": food101_results_effnetb2[\"test_loss\"][-1].item(),\n",
        "    \"test_acc\": food101_results_effnetb2[\"test_acc\"][-1].item(),\n",
        "    \"model_size (MB)\": food101_effnetb2_size\n",
        "}\n",
        "\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdRUFFbNzECe",
        "outputId": "6ae08756-56ae-4db0-e5e0-e3dfe1c234cd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 2.231266975402832,\n",
              " 'test_acc': 0.5964398980140686,\n",
              " 'model_size (MB)': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK04BX4EddOz"
      },
      "source": [
        "## 4. Creating a ViT feature extractor\n",
        "\n",
        "\n",
        "We'll start by creating a function called `create_vit_model()` which will be very similar to `create_effnetb2_model()` except of course returning a ViT feature extractor model and transforms rather than EffNetB2.\n",
        "\n",
        "Another slight difference is that `torchvision.models.vit_b_16()`'s output layer is called `heads` rather than `classifier`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HQoiI6jyddO0"
      },
      "outputs": [],
      "source": [
        "def create_vit_model(num_classes, \n",
        "                     seed):\n",
        "    \"\"\"Creates a ViT-B/16 feature extractor model and transforms.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int, optional): number of target classes.\n",
        "        seed (int, optional): random seed value for output layer. Defaults to 42.\n",
        "\n",
        "    Returns:\n",
        "        model (torch.nn.Module): ViT-B/16 feature extractor model. \n",
        "        transforms (torchvision.transforms): ViT-B/16 image transforms.\n",
        "    \"\"\"\n",
        "    # Create ViT_B_16 pretrained weights, transforms and model\n",
        "    weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "    vit_transforms = weights.transforms()\n",
        "    vit = torchvision.models.vit_b_16(weights=weights)\n",
        "\n",
        "    # Freeze all layers in model\n",
        "    for param in vit.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Change classifier head to suit our needs (this will be trainable)\n",
        "    torch.manual_seed(seed)\n",
        "    vit.heads = nn.Sequential(nn.Linear(in_features=768, # keep this the same as original model\n",
        "                                          out_features=num_classes)) # update to reflect target number of classes\n",
        "    \n",
        "    return vit, vit_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KI1dh24rddO1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d54ca77e79814bc0b0af4add34e6935f",
            "4cf52d09b0124f76914329b3bba500ac",
            "61865f4b8f164c589739107233174511",
            "d8705e6fd7db47469cbc2c8d34526626",
            "96cc08dcf8a24da3aaf63195b38719be",
            "24ad90fbb2fc44b9b13f7ac2a8e994c1",
            "b07193691d0d4f72bcaede756cb39606",
            "44f02d1012c040658d028a4f14b4a663",
            "f0ffd6e023614e6ca059f884b36b93b4",
            "acaf74a523e14d1cb584c42da06e493a",
            "3d12afe59ef443df8094eecae1e830e4"
          ]
        },
        "outputId": "2210d9a2-6c85-43f6-e229-bff2ad431ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/330M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d54ca77e79814bc0b0af4add34e6935f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create ViT model and transforms\n",
        "vit, vit_transforms = create_vit_model(num_classes=101,\n",
        "                                       seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "food101_vit_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.TrivialAugmentWide(),\n",
        "    vit_transforms\n",
        "])"
      ],
      "metadata": {
        "id": "W3Z7KpSTRitZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZknFrftsddO2"
      },
      "source": [
        "### Create DataLoaders for ViT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the optimizer\n",
        "optimizer = torch.optim.Adam(params=vit.parameters(), \n",
        "                              lr=1e-3)\n",
        "\n",
        "# Setup the loss function for multi-class classification\n",
        "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "accuracy_fn = Accuracy().to(device)\n",
        "\n",
        "from pathlib import Path\n",
        "data_dir = Path(\"data2\")\n",
        "\n",
        "train_dataset = datasets.Food101(root=data_dir, \n",
        "                                 split=\"train\", \n",
        "                                 transform=food101_vit_transforms,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.Food101(root=data_dir, \n",
        "                                 split=\"test\", \n",
        "                                 transform=food101_vit_transforms,\n",
        "                                 download=True)\n",
        "\n",
        "# train_dir = \"data/food101_20_percent/train\"\n",
        "# test_dir = \"data/food101_20_percent/test\"\n",
        "\n",
        "\n",
        "# train_dataset = datasets.ImageFolder(root=train_dir, transform=food101_vitb16_transforms)\n",
        "# test_dataset = datasets.ImageFolder(root=test_dir, transform=food101_vitb16_transforms)\n",
        "\n",
        "BATCH_SIZE=32\n",
        "NUM_WORKERS = 2\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                shuffle=True,\n",
        "                                num_workers=NUM_WORKERS)\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                shuffle=False,\n",
        "                                num_workers=NUM_WORKERS)\n",
        "\n",
        "def train_step(model, dataloader, loss_fn, accuracy_fn, optimizer, device):\n",
        "  model.train()\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model, dataloader, loss_fn, accuracy_fn, device):\n",
        "  model.eval()\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      test_pred = model(X)\n",
        "      loss = loss_fn(test_pred, y)\n",
        "      test_loss += loss\n",
        "      test_acc += accuracy_fn(test_pred, y)\n",
        "\n",
        "    test_loss /= len(dataloader)\n",
        "    test_acc /= len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "def train(model, train_dataloader, test_dataloader, loss_fn, accuracy_fn, optimizer, epochs, device):\n",
        "  from tqdm.auto import tqdm\n",
        "\n",
        "  results = {\"train_loss\":[],\n",
        "             \"train_acc\":[],\n",
        "             \"test_loss\":[],\n",
        "             \"test_acc\":[]\n",
        "             }\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model, train_dataloader, loss_fn, accuracy_fn, optimizer, device)\n",
        "    test_loss, test_acc = test_step(model, test_dataloader, loss_fn, accuracy_fn, device)\n",
        "  \n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1} | train_loss: {train_loss:.4f} train_acc: {train_acc:.2f}% | test_loss: {test_loss:.4f} test_acc: {test_acc:.2f}%\")\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "sbFPUhJelE99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3bf36dee0b5e4a588d0e314bb1a337c1",
            "47e4ee23a22e42e994dbbe783af597b5",
            "38206fa1261742f59f9f9d6b1d88e25d",
            "6014d705a4ff49169bddb7559c43aa44",
            "b975c407a29541038684e3be84df00e7",
            "c5930e5570a844e4877153048754d3de",
            "ad1ba6f47b43487297f484d131f593a6",
            "94a2164e9f814296ab1f7060e024b38c",
            "fe845a6a86814fad9f6816c512d08524",
            "534af872b3424105a4dc9dae31beb024",
            "152bffe848d6451b8a482e353e60c9c1"
          ]
        },
        "outputId": "0f84a041-eec8-4d50-9690-1487cc7a7ff2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz to data2/food-101.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4996278331 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bf36dee0b5e4a588d0e314bb1a337c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data2/food-101.tar.gz to data2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_Ew3AeiddO3"
      },
      "source": [
        "### Training ViT feature extractor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seeds()\n",
        "food101_results_vit = train(vit.to(device),train_dataloader,test_dataloader,loss_fn,accuracy_fn,optimizer,5,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "3e1ddd75210842b1b6032a00cb72346b",
            "fcd36c20f78743f9b1562c52dac39390",
            "28f7c2429aef42659f9442a36e90c0c4",
            "b38afa012245408da9661553425f72e6",
            "a01018e9acd2483f9d8cbcea73975615",
            "0c5681c20c54416fb76381723b26d580",
            "b6a1b8cc99d043b9a9ac3d2fdaebc767",
            "16df436943fb45c4abd5ea0294671d8b",
            "ba06548912f749b894617a8452461645",
            "894e4910bc6b4b9fa8574bddde5e21a2",
            "3a63fa36523b492cb91423220f398f0f"
          ]
        },
        "id": "kgBj38YTldNF",
        "outputId": "af412c25-8323-46fc-9ba3-601b64872cb2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e1ddd75210842b1b6032a00cb72346b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 2.3348 train_acc: 0.56% | test_loss: 1.9544 test_acc: 0.67%\n",
            "Epoch: 2 | train_loss: 2.0372 train_acc: 0.65% | test_loss: 1.8921 test_acc: 0.69%\n",
            "Epoch: 3 | train_loss: 1.9760 train_acc: 0.67% | test_loss: 1.8786 test_acc: 0.69%\n",
            "Epoch: 4 | train_loss: 1.9363 train_acc: 0.69% | test_loss: 1.8781 test_acc: 0.70%\n",
            "Epoch: 5 | train_loss: 1.9171 train_acc: 0.69% | test_loss: 1.8783 test_acc: 0.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgDjkjxkddO4"
      },
      "source": [
        "### Inspecting ViT loss curves\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS-Els6qddPU"
      },
      "source": [
        "Those are some nice looking loss curves. Just like our EffNetB2 feature extractor model, it looks our ViT model might benefit from a little longer training time and perhaps some [data augmentation](https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-transforms-data-augmentation) (to help prevent overfitting). "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot loss curves\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "train_loss=[]\n",
        "train_acc=[]\n",
        "test_loss=[]\n",
        "test_acc=[]\n",
        "for i in range(len(food101_results_vit[\"train_loss\"])):\n",
        "  tr_loss = food101_results_vit[\"train_loss\"][i].cpu().detach().numpy().item()\n",
        "  tr_acc = food101_results_vit[\"train_acc\"][i].cpu().detach().numpy().item()\n",
        "  te_loss = food101_results_vit[\"test_loss\"][i].cpu().detach().numpy().item()\n",
        "  te_acc = food101_results_vit[\"test_acc\"][i].cpu().detach().numpy().item()\n",
        "\n",
        "  train_loss.append(tr_loss)\n",
        "  train_acc.append(tr_acc)\n",
        "  test_loss.append(te_loss)\n",
        "  test_acc.append(te_acc)\n",
        "\n",
        "epochs = range(len(food101_results_vit[\"train_loss\"]))\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, train_loss, label = \"train_loss\")\n",
        "plt.plot(epochs, test_loss, label = \"test_loss\")\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, train_acc, label = \"train_acc\")\n",
        "plt.plot(epochs, test_acc, label = \"test_acc\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "GS1cMshuvAdo",
        "outputId": "092e8794-a6fa-4e11-f6ee-ffe1796dfd03"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMGEHfFnddPW"
      },
      "source": [
        "### Saving ViT feature extractor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
        "torch.save(vit.state_dict(),\n",
        "           f=\"models/food101_vit_feature_extractor_101classes.pth\")"
      ],
      "metadata": {
        "id": "xbmR4sV_S-cK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_food101_vit, vit_transforms = create_vit_model(num_classes=101, seed=42)\n",
        "\n",
        "loaded_food101_vit.load_state_dict(torch.load(\"models/food101_vit_feature_extractor_101classes.pth\", map_location=torch.device('cpu')))\n",
        "\n",
        "# loaded_food101_vit.load_state_dict(torch.load(\"models/food101_vit_feature_extractor_101classes.pth\"))"
      ],
      "metadata": {
        "id": "co24lUn3v1Zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa6ca3a-888d-4ddf-ba80-990a8da67882"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfjMerXtddPd"
      },
      "source": [
        "### Checking the size of ViT feature extractor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "food101_vit_size = Path(\"models/food101_vit_feature_extractor_101classes.pth\").stat().st_size // 1024**2\n",
        "print(f\"The Food101 ViTb16 feature extractor model size is {food101_vit_size} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOZEX752vT4v",
        "outputId": "2b2a9174-3656-4d8d-ecc6-370c4a969cd7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Food101 ViTb16 feature extractor model size is 327 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRJ07jVtddPl"
      },
      "source": [
        "### Collecting ViT feature extractor stats\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit_stats = {\n",
        "    \"test_loss\": food101_results_vit[\"test_loss\"][-1].item(),\n",
        "    \"test_acc\": food101_results_vit[\"test_acc\"][-1].item(),\n",
        "    \"model_size (MB)\": food101_vit_size\n",
        "}\n",
        "\n",
        "vit_stats"
      ],
      "metadata": {
        "id": "4G8iFQHcXjzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6105ebe-1d38-42ac-8000-72e60e65d3be"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 1.8783392906188965,\n",
              " 'test_acc': 0.6991297602653503,\n",
              " 'model_size (MB)': 327}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4S9Pmv5ddPm"
      },
      "source": [
        "## 5. Making predictions with our trained models and timing them\n",
        "\n",
        "We've got a couple of trained models, now how about we test them out doing what we'd like them to do?\n",
        "\n",
        "As in, let's see how they go making predictions (performing inference).\n",
        "\n",
        "\n",
        "To find out how long each of our models take to performance inference, let's create a function called `pred_and_store()` to iterate over each of the test dataset images one by one and perform a prediction. \n",
        "\n",
        "We'll time each of the predictions as well as store the results in a common prediction format: a list of dictionaries (where each element in the list is a single prediction and each sinlge prediction is a dictionary). \n",
        "\n",
        "> **Note:** We time the predictions one by one rather than by batch because when our model is deployed, it will likely only be making a prediction on one image at a time. As in, someone takes a photo and our model predicts on that single image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFmS5wm7ddPn"
      },
      "source": [
        "### Creating a function to make predictions across the test dataset\n",
        "\n",
        "Now we've got a list of our test image paths, let's get to work on our `pred_and_store()` function:\n",
        "\n",
        "1. Create a function that takes a list of paths, a trained PyTorch model, a series of transforms (to prepare images), a list of target class names and a target device.\n",
        "2. Create an empty list to store prediction dictionaries (we want the function to return a list of dictionaries, one for each prediction).\n",
        "3. Loop through the target input paths (steps 4-14 will happen inside the loop).\n",
        "4. Create an empty dictionary for each iteration in the loop to store prediction values per sample.\n",
        "5. Get the sample path and ground truth class name (we can do this by infering the class from the path).\n",
        "6. Start the prediction timer using Python's [`timeit.default_timer()`](https://docs.python.org/3/library/timeit.html#timeit.default_timer).\n",
        "7. Open the image using [`PIL.Image.open(path)`](https://pillow.readthedocs.io/en/stable/reference/Image.html#functions).\n",
        "8. Transform the image so it's capable of being using with the target model as well as add a batch dimension and send the image to the target device.\n",
        "9. Prepare the model for inference by sending it to the target device and turning on `eval()` mode.\n",
        "10. Turn on [`torch.inference_mode()`](https://pytorch.org/docs/stable/generated/torch.inference_mode.html) and pass the target transformed image to the model and calculate the prediction probability using `torch.softmax()` and the target label using `torch.argmax()`.\n",
        "11. Add the prediction probability and prediction class to the prediction dictionary created in step 4. Also make sure the prediction probability is on the CPU so it can be used with non-GPU libraries such as NumPy and pandas for later inspection.\n",
        "12. End the prediction timer started in step 6 and add the time to the prediction dictionary created in step 4.\n",
        "13. See if the predicted class matches the ground truth class from step 5 and add the result to the prediction dictionary created in step 4.\n",
        "14. Append the updated prediction dictionary to the empty list of predictions created in step 2.\n",
        "15. Return the list of prediction dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "JVuFhT6nddPn"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from timeit import default_timer as timer \n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Create a function to return a list of dictionaries with sample, truth label, prediction, prediction probability and prediction time\n",
        "def pred_and_store(paths, \n",
        "                   model,\n",
        "                   transform, \n",
        "                   class_names, \n",
        "                   device):\n",
        "    \n",
        "    # 2. Create an empty list to store prediction dictionaires\n",
        "    pred_list = []\n",
        "    \n",
        "    # 3. Loop through target paths\n",
        "    for path in tqdm(paths):\n",
        "        \n",
        "        # 4. Create empty dictionary to store prediction information for each sample\n",
        "        pred_dict = {}\n",
        "\n",
        "        # 5. Get the sample path and ground truth class name\n",
        "        pred_dict[\"image_path\"] = path\n",
        "        class_name = path.parent.stem\n",
        "        pred_dict[\"class_name\"] = class_name\n",
        "        \n",
        "        # 6. Start the prediction timer\n",
        "        start_time = timer()\n",
        "        \n",
        "        # 7. Open image path\n",
        "        img = Image.open(path)\n",
        "        \n",
        "        # 8. Transform the image, add batch dimension and put image on target device\n",
        "        transformed_image = transform(img).unsqueeze(0).to(device) \n",
        "        \n",
        "        # 9. Prepare model for inference by sending it to target device and turning on eval() mode\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        \n",
        "        # 10. Get prediction probability, predicition label and prediction class\n",
        "        with torch.inference_mode():\n",
        "            pred_logit = model(transformed_image) # perform inference on target sample \n",
        "            pred_prob = torch.softmax(pred_logit, dim=1) # turn logits into prediction probabilities\n",
        "            pred_label = torch.argmax(pred_prob, dim=1) # turn prediction probabilities into prediction label\n",
        "            pred_class = class_names[pred_label.cpu()] # hardcode prediction class to be on CPU\n",
        "\n",
        "            # 11. Make sure things in the dictionary are on CPU (required for inspecting predictions later on) \n",
        "            pred_dict[\"pred_prob\"] = round(pred_prob.unsqueeze(0).max().cpu().item(), 4)\n",
        "            pred_dict[\"pred_class\"] = pred_class\n",
        "            \n",
        "            # 12. End the timer and calculate time per pred\n",
        "            end_time = timer()\n",
        "            pred_dict[\"time_for_pred\"] = round(end_time-start_time, 4)\n",
        "\n",
        "        # 13. Does the pred match the true label?\n",
        "        pred_dict[\"correct\"] = class_name == pred_class\n",
        "\n",
        "        # 14. Add the dictionary to the list of preds\n",
        "        pred_list.append(pred_dict)\n",
        "    \n",
        "    # 15. Return list of prediction dictionaries\n",
        "    return pred_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "c_fD7630ddPm",
        "outputId": "39820bfe-bcb7-4964-ba84-6f4fd50d7fbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Finding all filepaths ending with '.jpg' in directory: data/food101_20_percent/test\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('data/food101_20_percent/test/tiramisu/2248428.jpg'),\n",
              " PosixPath('data/food101_20_percent/test/tiramisu/3840092.jpg'),\n",
              " PosixPath('data/food101_20_percent/test/tiramisu/2667065.jpg'),\n",
              " PosixPath('data/food101_20_percent/test/tiramisu/2167972.jpg'),\n",
              " PosixPath('data/food101_20_percent/test/tiramisu/2636790.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "test_dir = \"data/food101_20_percent/test\"\n",
        "\n",
        "# Get all test data paths\n",
        "print(f\"[INFO] Finding all filepaths ending with '.jpg' in directory: {test_dir}\")\n",
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "test_data_paths[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kll_Iix6ddPo"
      },
      "source": [
        "### Making and timing predictions with EffNetB2\n",
        "\n",
        "Let's start by using it to make predictions across the test dataset with our EffNetB2 model, paying attention to two details:\n",
        "\n",
        "1. **Device** - We'll hard code the `device` parameter to use `\"cpu\"` because when we deploy our model, we won't always have access to a `\"cuda\"` (GPU) device.\n",
        "    * Making the predictions on CPU will be a good indicator of speed of inference too because generally predictions on CPU devices are slower than GPU devices.\n",
        "2. **Transforms** - We'll also be sure to set the `transform` parameter to `effnetb2_transforms` to make sure the images are opened and transformed in the same way our `effnetb2` model has been trained on. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_test_pred = pred_and_store(paths=test_data_paths,\n",
        "                                    model=loaded_effnetb2_food101,\n",
        "                                    transform=food101_effnetb2_transforms,\n",
        "                                    class_names=class_names,\n",
        "                                    device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c30a7dc195e04f05acfed9971f363f2a",
            "c69670fa60a64e0b9c04b2934f68bdbb",
            "2778d721292540b8b0d89b1079d3bf8f",
            "5512f36509eb43799cdabc7a70668a10",
            "516c2567532c47bb9725df0be0d6c442",
            "808dac78e6124168a95209d03c8cc4bb",
            "7d0d2833059b453ba02e147dc14c2385",
            "7f0f9eefbedb429caaa4d565639155ca",
            "3ccc2510b9fa4db2886fc07545397b9b",
            "2268a23b9f564b129278071d938a25da",
            "66c5e963ff734ad1a2cdaf671778290e"
          ]
        },
        "id": "sTyDWn3g48gl",
        "outputId": "158235f7-ee19-4911-ee01-3bfd78d3dfbb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5050 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c30a7dc195e04f05acfed9971f363f2a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "effnetb2_test_pred_df = pd.DataFrame(effnetb2_test_pred)\n",
        "effnetb2_test_pred_df[\"correct\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq37NGRqUmOI",
        "outputId": "10b60c78-a56e-4907-be6e-18777794bf07"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     3008\n",
              "False    2042\n",
              "Name: correct, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_stats[\"time_for_pred\"] = round(effnetb2_test_pred_df[\"time_for_pred\"].mean(), 4)\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiLdq01-7gaE",
        "outputId": "65f85f81-729f-466a-a719-40df46f38b82"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 2.231266975402832,\n",
              " 'test_acc': 0.5964398980140686,\n",
              " 'model_size (MB)': 30,\n",
              " 'time_for_pred': 0.0312}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZQoCQPKddQC"
      },
      "source": [
        "### Making and timing predictions with ViT \n",
        "\n",
        "We've made predictions with our EffNetB2 model, now let's do the same for our ViT model.\n",
        "\n",
        "To do so, we can use the `pred_and_store()` function we created above except this time we'll pass in our `vit` model as well as the `vit_transforms`.\n",
        "\n",
        "And we'll keep the predictions on the CPU via `device=\"cpu\"` (a natural extension here would be to test the prediction times on CPU and on GPU)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit_test_pred = pred_and_store(paths=test_data_paths,\n",
        "                                    model=loaded_food101_vit,\n",
        "                                    transform=food101_vit_transforms,\n",
        "                                    class_names=class_names,\n",
        "                                    device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e1443be3a38f4d36a40d92d956e92678",
            "8732ef3848fa4ccea4d62fbd10aff94a",
            "8cb07ea8ee4b497eb62c8242a5dfb4e8",
            "6355c09d17e04811aafbf6764bddbc66",
            "a754e72a66024771a801fba13d05a340",
            "094ce8bfdb284a81a37f23ddee64176b",
            "3888a252ce0148509c1a4d2ebfdcf18c",
            "692e58c53b194bc683f6fb5bdd7d6e5d",
            "35fe2554182f4ff1bbbb43891dcc99be",
            "5e8966e1b2374f059c1287952f60a6cc",
            "e280ee8b7aba4abb996eb470c9653cf0"
          ]
        },
        "id": "QcOLltwvN8aL",
        "outputId": "5662d4c0-21ee-4da2-ff99-3ff977187966"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5050 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1443be3a38f4d36a40d92d956e92678"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "vit_test_pred_df = pd.DataFrame(vit_test_pred)\n",
        "vit_test_pred_df[\"correct\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gve0ssIJVNIt",
        "outputId": "ae5f7097-ce63-4cf5-ddcd-d73dadd6a935"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     3486\n",
              "False    1564\n",
              "Name: correct, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit_test_pred[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4lV11f-UZNk",
        "outputId": "1b615291-e24f-466d-ff6a-63a74e2fc782"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'image_path': PosixPath('data/food101_20_percent/test/scallops/497432.jpg'),\n",
              "  'class_name': 'scallops',\n",
              "  'pred_prob': 0.2544,\n",
              "  'pred_class': 'oysters',\n",
              "  'time_for_pred': 0.2951,\n",
              "  'correct': False},\n",
              " {'image_path': PosixPath('data/food101_20_percent/test/scallops/1479757.jpg'),\n",
              "  'class_name': 'scallops',\n",
              "  'pred_prob': 0.4602,\n",
              "  'pred_class': 'scallops',\n",
              "  'time_for_pred': 0.0406,\n",
              "  'correct': True}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit_stats[\"time_for_pred\"] = round(vit_test_pred_df[\"time_for_pred\"].mean(),4)\n",
        "vit_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J7ptVbL62SG",
        "outputId": "36e62a37-bf00-42d6-c772-7aa220a5f8d5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 1.8783392906188965,\n",
              " 'test_acc': 0.6991297602653503,\n",
              " 'model_size (MB)': 327,\n",
              " 'time_for_pred': 0.023}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrReBHAFddQG"
      },
      "source": [
        "## 6. Comparing model results, prediction times and size\n",
        "\n",
        "Our two best model contenders have been trained and evaluated.\n",
        "\n",
        "Now let's put them head to head and compare across their different statistics.\n",
        "\n",
        "To do so, let's turn our `effnetb2_stats` and `vit_stats` dictionaries into a pandas DataFrame.\n",
        "\n",
        "We'll add a column to view the model names as well as the convert the test accuracy to a whole percentage rather than decimal."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_results = pd.DataFrame([effnetb2_stats, vit_stats])\n",
        "\n",
        "models_results[\"model\"] = [\"effnetb2\", \"vitb16\"]\n",
        "\n",
        "models_results[\"test_acc\"] = round(models_results.test_acc *100, 4)\n",
        "\n",
        "models_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "ELt7S1kV78zR",
        "outputId": "38008fb2-554b-4ca7-9dc6-201c4a506d1b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   test_loss  test_acc  model_size (MB)  time_for_pred     model\n",
              "0   2.231267    59.644               30         0.0312  effnetb2\n",
              "1   1.878339    69.913              327         0.0230    vitb16"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8154e0f1-eab6-4b32-96aa-a07bbed0b1d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "      <th>model_size (MB)</th>\n",
              "      <th>time_for_pred</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.231267</td>\n",
              "      <td>59.644</td>\n",
              "      <td>30</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>effnetb2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.878339</td>\n",
              "      <td>69.913</td>\n",
              "      <td>327</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>vitb16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8154e0f1-eab6-4b32-96aa-a07bbed0b1d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8154e0f1-eab6-4b32-96aa-a07bbed0b1d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8154e0f1-eab6-4b32-96aa-a07bbed0b1d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvb9_VzeddQI"
      },
      "source": [
        "It seems our ViT model outperforms the EffNetB2 model across the performance metrics (test loss, where lower is better and test accuracy, where higher is better) but at the expense of having:\n",
        "* 11x+ the number of parameters.\n",
        "* 11x+ the model size. \n",
        "\n",
        "Are these tradeoffs worth it?\n",
        "\n",
        "Perhaps if we had unlimited compute power but for our use case of deploying the FoodVision Mini model to a smaller device (e.g. a mobile phone), we'd likely start out with the EffNetB2 model for faster predictions at a slightly reduced performance but dramatically smaller "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQGGqIxGddQK"
      },
      "source": [
        "## 7. Bringing Food101 to life by creating a Gradio demo\n",
        "\n",
        "We've decided we'd like to deploy the EffNetB2 model.\n",
        "\n",
        "\n",
        "There are several ways to deploy a machine learning model each with specific use cases (as discussed above).\n",
        "\n",
        "We're going to be focused on perhaps the quickest and certainly one of the most fun ways to get a model deployed to the internet.\n",
        "\n",
        "And that's by using [Gradio](https://gradio.app/).\n",
        "\n",
        "What's Gradio?\n",
        "\n",
        "\n",
        "> Gradio is the fastest way to demo your machine learning model with a friendly web interface so that anyone can use it, anywhere!\n",
        "\n",
        "Why create a demo of your models?\n",
        "\n",
        "Because metrics on the test set look nice but you never really know how you're model performs until you use it in the wild.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import gradio as gr\n",
        "except:\n",
        "  !pip -q install gradio\n",
        "  import gradio as gr\n",
        "\n",
        "print(f\"Gradio version: {gr.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuID6v-4B_jA",
        "outputId": "d8d12a94-e9c9-4312-b874-57811d47d181"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.3 MB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 69.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 36.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 270 kB 42.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 48.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 593 kB 59.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 34.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 56.2 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Gradio version: 3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvMb6gyZddQL"
      },
      "source": [
        "### Gradio overview\n",
        "\n",
        "The overall premise of Gradio is very similar to what we've been repeating throughout the course.\n",
        "\n",
        "What are our **inputs** and **outputs**?\n",
        "\n",
        "And how should we get there?\n",
        "\n",
        "Well that's what our machine learning model does.\n",
        "\n",
        "```\n",
        "inputs -> ML model -> outputs\n",
        "```\n",
        "\n",
        "\n",
        "Though the concepts of inputs and outputs can be bridged to almost any other kind of ML problem.\n",
        "\n",
        "Your inputs and outputs might be any combination of the following:\n",
        "* Images\n",
        "* Text\n",
        "* Video\n",
        "* Tabular data\n",
        "* Audio\n",
        "* Numbers\n",
        "* & more\n",
        "\n",
        "And the ML model you build will depend on your inputs and outputs.\n",
        "\n",
        "Gradio emulates this paradigm by creating an interface ([`gradio.Interface()`](https://gradio.app/docs/#interface-header)) to from inputs to outputs.\n",
        "\n",
        "```\n",
        "gradio.Interface(fn, inputs, outputs)\n",
        "```\n",
        "\n",
        "Where, `fn` is a Python function to map the `inputs` to the `outputs`.\n",
        "\n",
        "\n",
        "*Gradio provides a very helpful `Interface` class to easily create an inputs -> model/function -> outputs workflow where the inputs and outputs could be almost anything you want. For example, you might input Tweets (text) to see if they're about machine learning or not or [input a text prompt to generate images](https://huggingface.co/blog/stable_diffusion).*\n",
        "\n",
        "> **Note:** Gradio has a vast number of possible `inputs` and `outputs` options known as \"Components\" from images to text to numbers to audio to videos and more. You can see all of these in the [Gradio Components documentation](https://gradio.app/docs/#components)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8uUMwT5ddQL"
      },
      "source": [
        "### Creating a function to map our inputs and outputs\n",
        "\n",
        "To create our FoodVision Mini demo with Gradio, we'll need a function to map our inputs to our outputs.\n",
        "\n",
        "We created a function earlier called `pred_and_store()` to make predictions with a given model across a list of target files and store them in a list of dictionaries.\n",
        "\n",
        "How about we create a similar function but this time focusing on a making a prediction on a single image with our EffNetB2 model?\n",
        "\n",
        "More specifically, we want a function that takes an image as input, preprocesses (transforms) it, makes a prediction with EffNetB2 and then returns the prediction (pred or pred label for short) as well as the prediction probability (pred prob).\n",
        "\n",
        "And while we're here, let's return the time it took to do so too:\n",
        "\n",
        "```\n",
        "input: image -> transform -> predict with EffNetB2 -> output: pred, pred prob, time taken\n",
        "```\n",
        "\n",
        "This will be our `fn` parameter for our Gradio interface.\n",
        "\n",
        "First, let's make sure our EffNetB2 model is on the CPU (since we're sticking with CPU-only predictions, however you could change this if you have access to a GPU)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def effnetb2_predict(img):\n",
        "  \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
        "  \"\"\"\n",
        "  # Start the timer\n",
        "  start_time = timer()\n",
        "    \n",
        "  # Transform the target image and add a batch dimension\n",
        "  img = food101_effnetb2_transforms(img).unsqueeze(0)\n",
        "    \n",
        "  # Put model into evaluation mode and turn on inference mode\n",
        "  effnetb2.to(device)\n",
        "  effnetb2.eval()\n",
        "  with torch.inference_mode():\n",
        "    # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
        "    pred_probs = torch.softmax(effnetb2(img), dim=1)\n",
        "    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)\n",
        "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "    \n",
        "    # Calculate the prediction time\n",
        "    pred_time = round(timer() - start_time, 5)\n",
        "    \n",
        "  # Return the prediction dictionary and prediction time \n",
        "  return pred_labels_and_probs, pred_time"
      ],
      "metadata": {
        "id": "VlHw2txxCz1n"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def effnetb2_predict(img):\n",
        "    \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
        "    \"\"\"\n",
        "    # Start the timer\n",
        "    start_time = timer()\n",
        "    \n",
        "    # Transform the target image and add a batch dimension\n",
        "    img = effnetb2_transforms(img).unsqueeze(0)\n",
        "    \n",
        "    # Put model into evaluation mode and turn on inference mode\n",
        "    effnetb2.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
        "        pred_probs = torch.softmax(effnetb2(img), dim=1)\n",
        "    \n",
        "    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)\n",
        "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "    \n",
        "    # Calculate the prediction time\n",
        "    pred_time = round(timer() - start_time, 5)\n",
        "    \n",
        "    # Return the prediction dictionary and prediction time \n",
        "    return pred_labels_and_probs, pred_time"
      ],
      "metadata": {
        "id": "SaHugoASurK7"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "\n",
        "# Create a list of example inputs to our Gradio demo\n",
        "example_list = [[str(filepath)] for filepath in random.sample(test_data_paths, k=3)]\n",
        "example_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gMHpVNGD7R8",
        "outputId": "c0e2b419-a75a-45df-fa13-866d4e88ee80"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['data/food101_20_percent/test/churros/1980483.jpg'],\n",
              " ['data/food101_20_percent/test/edamame/1191326.jpg'],\n",
              " ['data/food101_20_percent/test/ceviche/3833117.jpg']]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANZ-a58uddQk"
      },
      "source": [
        "### Building a Gradio interface\n",
        "\n",
        "\n",
        "Let's create a Gradio interface to replicate the workflow:\n",
        "\n",
        "```\n",
        "input: image -> transform -> predict with EffNetB2 -> output: pred, pred prob, time taken\n",
        "```\n",
        "\n",
        "We can do with the [`gradio.Interface()`](https://gradio.app/docs/#interface) class with the following parameters:\n",
        "* `fn` - a Python function to map `inputs` to `outputs`, in our case, we'll use our `predict()` function.\n",
        "* `inputs` - the input to our interface, such as an image using [`gradio.Image()`](https://gradio.app/docs/#image) or `\"image\"`. \n",
        "* `outputs` - the output of our interface once the `inputs` have gone through the `fn`, such as a label using [`gradio.Label()`](https://gradio.app/docs/#label) (for our model's predicted labels) or number using [`gradio.Number()`](https://gradio.app/docs/#number) (for our model's prediction time).\n",
        "    * **Note:** Gradio comes with many in-built `inputs` and `outputs` options known as [\"Components\"](https://gradio.app/docs/#components).\n",
        "* `examples` - a list of examples to showcase for the demo.\n",
        "* `title` - a string title of the demo.\n",
        "* `description` - a string description of the demo.\n",
        "* `article` - a reference note at the bottom of the demo.\n",
        "\n",
        "Once we've created our demo instance of `gr.Interface()`, we can bring it to life using [`gradio.Interface().launch()`](https://gradio.app/docs/#launch-header) or `demo.launch()` command. \n",
        "\n",
        "✌"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Create title, description and article strings\n",
        "title = \"Food101\"\n",
        "description = \"An EfficientNetB2 feature extractor computer vision model to classify images of food using whole Food101 dataset.\"\n",
        "article = \"Created at 07. PyTorch Model Deployment\"\n",
        "\n",
        "# Create the Gradio demo\n",
        "demo = gr.Interface(fn=effnetb2_predict, # mapping function from input to output\n",
        "                    inputs=gr.Image(type=\"pil\"), # what are the inputs?\n",
        "                    outputs=[gr.Label(num_top_classes=3, label=\"Predictions\"), # what are the outputs?\n",
        "                             gr.Number(label=\"Prediction time (s)\")], # our fn has two outputs, therefore we have two outputs\n",
        "                    examples=example_list, \n",
        "                    title=title,\n",
        "                    description=description,\n",
        "                    article=article)\n",
        "\n",
        "# Launch the demo!\n",
        "demo.launch(debug=False, # print errors locally?\n",
        "            share=True) # generate a publically shareable URL?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "WjIa4F-zBbtH",
        "outputId": "6af0c7bc-1c5c-4953-93c0-f801601fac14"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://22271.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://22271.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f2b912ad490>,\n",
              " 'http://127.0.0.1:7866/',\n",
              " 'https://22271.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vit_predict(img):\n",
        "    \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
        "    \"\"\"\n",
        "    # Start the timer\n",
        "    start_time = timer()\n",
        "    \n",
        "    # Transform the target image and add a batch dimension\n",
        "    img = food101_vit_transforms(img).unsqueeze(0)\n",
        "    \n",
        "    # Put model into evaluation mode and turn on inference mode\n",
        "    vit.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
        "        pred_probs = torch.softmax(vit(img), dim=1)\n",
        "    \n",
        "    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)\n",
        "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "    \n",
        "    # Calculate the prediction time\n",
        "    pred_time = round(timer() - start_time, 5)\n",
        "    \n",
        "    # Return the prediction dictionary and prediction time \n",
        "    return pred_labels_and_probs, pred_time"
      ],
      "metadata": {
        "id": "QiSgmJ71YDj6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "\n",
        "# Create a list of example inputs to our Gradio demo\n",
        "example_list = [[str(filepath)] for filepath in random.sample(test_data_paths, k=3)]\n",
        "example_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w-s3QJWYOIv",
        "outputId": "0ecba2e8-bb89-4f9b-fc20-e3a313659985"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['data/food101_20_percent/test/club_sandwich/2222753.jpg'],\n",
              " ['data/food101_20_percent/test/miso_soup/3098102.jpg'],\n",
              " ['data/food101_20_percent/test/chocolate_mousse/455627.jpg']]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Create title, description and article strings\n",
        "title = \"Food101\"\n",
        "description = \"A ViT-Base16 feature extractor computer vision model to classify images of food using whole Food101 dataset.\"\n",
        "article = \"Created at 07. PyTorch Model Deployment\"\n",
        "\n",
        "# Create the Gradio demo\n",
        "demo = gr.Interface(fn=vit_predict, # mapping function from input to output\n",
        "                    inputs=gr.Image(type=\"pil\"), # what are the inputs?\n",
        "                    outputs=[gr.Label(num_top_classes=3, label=\"Predictions\"), # what are the outputs?\n",
        "                             gr.Number(label=\"Prediction time (s)\")], # our fn has two outputs, therefore we have two outputs\n",
        "                    examples=example_list, \n",
        "                    title=title,\n",
        "                    description=description,\n",
        "                    article=article)\n",
        "\n",
        "# Launch the demo!\n",
        "demo.launch(debug=False, # print errors locally?\n",
        "            share=True) # generate a publically shareable URL?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "6YR5jvWzYTos",
        "outputId": "00448f69-8850-43bb-ace7-00ad9e9ef732"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://21872.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://21872.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f2b8e530a50>,\n",
              " 'http://127.0.0.1:7862/',\n",
              " 'https://21872.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmuP3gciddQn"
      },
      "source": [
        "## 8. Turning our Food101 Gradio Demo into a deployable app\n",
        "\n",
        "We've seen our Food101 model come to life through a Gradio demo.\n",
        "\n",
        "But what if we wanted to share it with our friends?\n",
        "\n",
        "Well, we could use the provided Gradio link, however, the shared link only lasts for 72-hours.\n",
        "\n",
        "To make it more permanent, we can package it into an app and upload it to [Hugging Face Spaces](https://huggingface.co/spaces/launch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr61DbaJddQn"
      },
      "source": [
        "### What is Hugging Face Spaces?\n",
        "\n",
        "Hugging Face Spaces is a resource that allows you to host and share machine learning apps.\n",
        "\n",
        "Building a demo is one of the best ways to showcase and test what you've done.\n",
        "\n",
        "And Spaces allows you to do just that.\n",
        "\n",
        "You can think of Hugging Face as the GitHub of machine learning.\n",
        "\n",
        "If having a good GitHub portfolio showcases your coding abilities, having a good Hugging Face portfolio can showcase your machine learning abilities.\n",
        "\n",
        "> **Note:** There are many other places we could upload and host our Gradio app such as, Google Cloud, AWS (Amazon Web Services) or other cloud vendors, however, we're going to use Hugging Face Spaces due to the ease of use and wide adoption by the machine learning community."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwypu2HSddQn"
      },
      "source": [
        "### Deployed Gradio app structure\n",
        "\n",
        "To upload our demo Gradio app, we'll want to put everything relating to it into a single directory.\n",
        "\n",
        "For example, our demo might live at the path `demos/food101/` with the file structure:\n",
        "\n",
        "```\n",
        "demos/\n",
        "└── foodvision_big/\n",
        "    ├── food101_effnetb2_feature_extractor_101classes.pth\n",
        "    ├── app.py\n",
        "    ├── class_names.txt\n",
        "    ├── examples/\n",
        "    │   ├── example_1.jpg\n",
        "    │   ├── example_2.jpg\n",
        "    │   └── example_3.jpg\n",
        "    ├── model.py\n",
        "    └── requirements.txt\n",
        "```\n",
        "\n",
        "Where:\n",
        "* `food101_effnetb2_feature_extractor_101classes.pth` is our trained PyTorch model file.\n",
        "* `app.py` contains our Gradio app (similar to the code that launched the app).\n",
        "    * **Note:** `app.py` is the default filename used for Hugging Face Spaces, if you deploy your app there, Spaces will by default look for a file called `app.py` to run. This is changable in settings.\n",
        "* `class_names.txt` contains all of the class names for FoodVision Big.\n",
        "* `examples/` contains example images to use with our Gradio app.\n",
        "* `model.py` contains the model defintion as well as any transforms assosciated with the model.\n",
        "* `requirements.txt` contains the dependencies to run our app such as `torch`, `torchvision` and `gradio`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxPJAv7pddQp"
      },
      "source": [
        "### Creating a `demos` folder to store our Food101 app files\n",
        "\n",
        "To begin, let's first create a `demos/` directory to store all of our Food101 app files.\n",
        "\n",
        "We can do with Python's [`pathlib.Path(\"path_to_dir\")`](https://docs.python.org/3/library/pathlib.html#basic-use) to establish the directory path and [`pathlib.Path(\"path_to_dir\").mkdir()`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir) to create it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "W4NqvSBsddQp"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Create FoodVision Big demo path\n",
        "foodvision_big_demo_path = Path(\"demos/foodvision_big/\")\n",
        "\n",
        "# Make FoodVision Big demo directory\n",
        "foodvision_big_demo_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqxVWJ5tddQp"
      },
      "source": [
        "### Creating a folder of example images to use with our FoodVision Mini demo\n",
        "\n",
        "Now we've got a directory to store our Food101 demo files, let's add some examples to it.\n",
        "\n",
        "Three example images from the test dataset should be enough.\n",
        "\n",
        "To do so we'll:\n",
        "1. Create an `examples/` directory within the `demos/foodvision_big` directory.\n",
        "2. Choose three random images from the test dataset and collect their filepaths in a list.\n",
        "3. Copy the three random images from the test dataset to the `demos/foodvision_big/examples/` directory."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make FoodVision Big demo examples directory\n",
        "(foodvision_big_demo_path / \"examples\").mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "GMtyIDsrZmnf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1MHpMSDNddQp",
        "outputId": "492027c4-5348-462d-c358-dcb5fb9548bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Copying data/food101_20_percent/test/apple_pie/1284428.jpg to demos/foodvision_big/examples/1284428.jpg\n",
            "[INFO] Copying data/food101_20_percent/test/cheesecake/124695.jpg to demos/foodvision_big/examples/124695.jpg\n",
            "[INFO] Copying data/food101_20_percent/test/pizza/177513.jpg to demos/foodvision_big/examples/177513.jpg\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Create an examples directory\n",
        "foodvision_big_examples_path = foodvision_big_demo_path / \"examples\"\n",
        "foodvision_big_examples_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Collect three random test dataset image paths\n",
        "foodvision_big_examples = [Path('data/food101_20_percent/test/apple_pie/1284428.jpg'),\n",
        "                            Path('data/food101_20_percent/test/cheesecake/124695.jpg'),\n",
        "                            Path('data/food101_20_percent/test/pizza/177513.jpg')]\n",
        "\n",
        "# 3. Copy the three random images to the examples directory\n",
        "for example in foodvision_big_examples:\n",
        "    destination = foodvision_big_examples_path / example.name\n",
        "    print(f\"[INFO] Copying {example} to {destination}\")\n",
        "    shutil.copy2(src=example, dst=destination)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFWOD5w3ddQq"
      },
      "source": [
        "Now to verify our examples are present, let's list the contents of our `demos/foodvision_big/examples/` directory with [`os.listdir()`](https://docs.python.org/3/library/os.html#os.listdir) and then format the filepaths into a list of lists (so it's compatible with Gradio's [`gradio.Interface()`](https://gradio.app/docs/#interface) `example` parameter)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DbAia8zIddQq",
        "outputId": "d54c34f2-58c9-4d8d-b5fb-64175eb1d39b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['examples/124695.jpg'], ['examples/177513.jpg'], ['examples/1284428.jpg']]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Get example filepaths in a list of lists\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(foodvision_big_examples_path)]\n",
        "example_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr5mDXzUddQq"
      },
      "source": [
        "### Moving our trained EffNetB2 model to our FoodVision Big demo directory\n",
        "\n",
        "We previously saved our Food101 EffNetB2 feature extractor model under `models/food101_effnetb2_feature_extractor_101classes.pth`.\n",
        "\n",
        "And rather double up on saved model files, let's move our model to our `demos/foodvision_big` directory.\n",
        "\n",
        "We can do so using Python's [`shutil.move()`](https://docs.python.org/3/library/shutil.html#shutil.move) method and passing in `src` (the source path of the target file) and `dst` (the destination path of the target file to be moved to) parameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "aym8Y92WddQq",
        "outputId": "1759f70a-6f48-4437-c05f-fdf10829c6e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Attempting to move models/food101_effnetb2_feature_extractor_101classes.pth to demos/foodvision_big/food101_effnetb2_feature_extractor_101classes.pth\n",
            "[INFO] Model move complete.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Create a source path for our target model\n",
        "effnetb2_foodvision_big_model_path = \"models/food101_effnetb2_feature_extractor_101classes.pth\"\n",
        "\n",
        "# Create a destination path for our target model \n",
        "effnetb2_foodvision_big_model_destination = foodvision_big_demo_path / effnetb2_foodvision_big_model_path.split(\"/\")[1]\n",
        "\n",
        "# Try to move the file\n",
        "try:\n",
        "    print(f\"[INFO] Attempting to move {effnetb2_foodvision_big_model_path} to {effnetb2_foodvision_big_model_destination}\")\n",
        "    \n",
        "    # Move the model\n",
        "    shutil.move(src=effnetb2_foodvision_big_model_path, \n",
        "                dst=effnetb2_foodvision_big_model_destination)\n",
        "    \n",
        "    print(f\"[INFO] Model move complete.\")\n",
        "\n",
        "# If the model has already been moved, check if it exists\n",
        "except:\n",
        "    print(f\"[INFO] No model found at {effnetb2_foodvision_big_model_path}, perhaps its already been moved?\")\n",
        "    print(f\"[INFO] Model exists at {effnetb2_foodvision_big_model_destination}: {effnetb2_foodvision_big_model_destination.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving Food101 class names to file (`class_names.txt`)\n",
        "\n",
        "Because there are so many classes in the Food101 dataset, instead of storing them as a list in our `app.py` file, let's saved them to a `.txt` file and read them in when necessary instead.\n",
        "\n",
        "We'll just remind ourselves what they look like first by checking out `food101_class_names`."
      ],
      "metadata": {
        "id": "H4BI55c-hUDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the first 10 Food101 class names\n",
        "class_names[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG2ciFRfhe7M",
        "outputId": "c490ea85-41da-407e-988a-b2aabaf0e257"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apple_pie',\n",
              " 'baby_back_ribs',\n",
              " 'baklava',\n",
              " 'beef_carpaccio',\n",
              " 'beef_tartare',\n",
              " 'beet_salad',\n",
              " 'beignets',\n",
              " 'bibimbap',\n",
              " 'bread_pudding',\n",
              " 'breakfast_burrito']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can write these to a text file by first creating a path to `demos/foodvision_big/class_names.txt` and then opening a file with Python's `open()` and then writing to it leaving a new line for each class.\n",
        "\n",
        "Ideally, we want our class names to be saved like:\n",
        "\n",
        "```\n",
        "apple_pie\n",
        "baby_back_ribs\n",
        "baklava\n",
        "beef_carpaccio\n",
        "beef_tartare\n",
        "...\n",
        "```"
      ],
      "metadata": {
        "id": "GE9JTRzfh5rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create path to Food101 class names\n",
        "foodvision_big_class_names_path = foodvision_big_demo_path / \"class_names.txt\"\n",
        "\n",
        "# Write Food101 class names list to file\n",
        "with open(foodvision_big_class_names_path, \"w\") as f:\n",
        "    print(f\"[INFO] Saving Food101 class names to {foodvision_big_class_names_path}\")\n",
        "    f.write(\"\\n\".join(class_names)) # leave a new line between each class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoLMo0FyhjW9",
        "outputId": "aaecb225-834d-4e99-fecb-431406e3436d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Saving Food101 class names to demos/foodvision_big/class_names.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now let's make sure we can read them in.\n",
        "\n",
        "To do so we'll use Python's [`open()`](https://www.w3schools.com/python/ref_func_open.asp) in read mode (`\"r\"`) and then use the [`readlines()`](https://www.w3schools.com/python/ref_file_readlines.asp) method to read each line of our `class_names.txt` file.\n",
        "\n",
        "And we can save the class names to a list by stripping the newline value of each of them with a list comprehension and [`strip()`](https://www.w3schools.com/python/ref_string_strip.asp). "
      ],
      "metadata": {
        "id": "0aDD_4CdiYZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open Food101 class names file and read each line into a list\n",
        "with open(foodvision_big_class_names_path, \"r\") as f:\n",
        "    food101_class_names_loaded = [food.strip() for food in  f.readlines()]\n",
        "    \n",
        "# View the first 5 class names loaded back in\n",
        "food101_class_names_loaded[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viPpSJ9qiain",
        "outputId": "6e95a84b-87d8-4de3-c9cc-91db78b3a116"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIMD2LJFddQr"
      },
      "source": [
        "### Turning our EffNetB2 model into a Python script (`model.py`)\n",
        "\n",
        "Our current model's `state_dict` is saved to `demos/foodvision_big/food101_effnetb2_feature_extractor_101classes.pth`.\n",
        "\n",
        "To load it in we can use `model.load_state_dict()` along with `torch.load()`.\n",
        "\n",
        "> **Note:** For a refresh on saving and loading a model (or a model's `state_dict` in PyTorch, see the PyTorch recipe for [What is a `state_dict` in PyTorch?](https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html)\n",
        "\n",
        "But before we can do this, we first need a way to instantiate a `model`.\n",
        "\n",
        "To do this in a modular fashion we'll create a script called `model.py` which contains our `create_effnetb2_model()` function we created before.\n",
        "\n",
        "That way we can import the function in *another* script (see `app.py` below) and then use it to create our EffNetB2 `model` instance as well as get its appropriate transforms.\n",
        "\n",
        "we'll use the `%%writefile path/to/file` magic command to turn a cell of code into a file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "psFsLgszddQr",
        "outputId": "1f7b68c1-c450-4052-c68e-077e3b5b54e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/foodvision_big/model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile demos/foodvision_big/model.py\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "def create_effnetb2_model(num_classes, \n",
        "                          seed):\n",
        "    \"\"\"Creates an EfficientNetB2 feature extractor model and transforms.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int, optional): number of classes in the classifier head. \n",
        "        seed (int, optional): random seed value. Defaults to 42.\n",
        "\n",
        "    Returns:\n",
        "        model (torch.nn.Module): EffNetB2 feature extractor model. \n",
        "        transforms (torchvision.transforms): EffNetB2 image transforms.\n",
        "    \"\"\"\n",
        "    # 1, 2, 3. Create EffNetB2 pretrained weights, transforms and model\n",
        "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "    effnetb2_transforms = weights.transforms()\n",
        "    effnetb2 = torchvision.models.efficientnet_b2(weights=weights)\n",
        "\n",
        "    # 4. Freeze all layers in base model\n",
        "    for param in effnetb2.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 5. Change classifier head with random seed for reproducibility\n",
        "    torch.manual_seed(seed)\n",
        "    effnetb2.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.3, inplace=True),\n",
        "        nn.Linear(in_features=1408, out_features=num_classes),\n",
        "    )\n",
        "    \n",
        "    return effnetb2, effnetb2_transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pyBex1CddQr"
      },
      "source": [
        "### Turning our FoodVision Big Gradio app into a Python script (`app.py`)\n",
        "\n",
        "We've now got a `model.py` script as well as a path to a saved model `state_dict` that we can load in.\n",
        "\n",
        "Time to construct `app.py`.\n",
        "\n",
        "We call it `app.py` because by default when you create a HuggingFace Space, it looks for a file called `app.py` to run and host (though you can change this in settings).\n",
        "\n",
        "Our `app.py` script will put together all of the pieces of the puzzle to create our Gradio demo and will have four main parts: \n",
        "\n",
        "1. **Imports and class names setup** - Here we'll import the various dependencies for our demo including the `create_effnetb2_model()` function from `model.py` as well as setup the different class names for our FoodVision Big app. \n",
        "2. **Model and transforms preparation** - Here we'll create an EffNetB2 model instance along with the transforms to go with it and then we'll load in the saved model weights/`state_dict`. When we load the model we'll also set `map_location=torch.device(\"cpu\")` in [`torch.load()`](https://pytorch.org/docs/stable/generated/torch.load.html) so our model gets loaded onto the CPU regardless of the device it trained on (we do this because we won't necessarily have a GPU when we deploy and we'll get an error if our model is trained on GPU but we try to deploy it to CPU without explicitly saying so).\n",
        "3. **Predict function** - Gradio's `gradio.Interface()` takes a `fn` parameter to map inputs to outputs, our `predict()` function will be the same as the one we defined before, it will take in an image and then use the loaded transforms to preprocess it before using the loaded model to make a prediction on it.\n",
        "    * **Note:** We'll have to create the example list on the fly via the `examples` parameter. We can do so by creating a list of the files inside the `examples/` directory with: `[[\"examples/\" + example] for example in os.listdir(\"examples\")]`.\n",
        "4. **Gradio app** - This is where the main logic of our demo will live, we'll create a `gradio.Interface()` instance called `demo` to put together our inputs, `predict()` function and outputs. And we'll finish the script by calling `demo.launch()` to launch our FoodVision Big demo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Z2nyS00HddQr",
        "outputId": "7dfcd118-3ba0-4a80-9de4-635a0bb3901c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting demos/foodvision_big/app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile demos/foodvision_big/app.py\n",
        "### 1. Imports and class names setup ### \n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from model import create_effnetb2_model\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# Setup class names\n",
        "with open(\"class_names.txt\", \"r\") as f: # reading them in from class_names.txt\n",
        "    class_names = [food_name.strip() for food_name in  f.readlines()]\n",
        "\n",
        "### 2. Model and transforms preparation ###\n",
        "\n",
        "# Create EffNetB2 model\n",
        "effnetb2, effnetb2_transforms = create_effnetb2_model(\n",
        "    num_classes=101,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Load saved weights\n",
        "effnetb2.load_state_dict(\n",
        "    torch.load(\n",
        "        f=\"food101_effnetb2_feature_extractor_101classes.pth\",\n",
        "        map_location=torch.device(\"cpu\"),  # load to CPU\n",
        "    )\n",
        ")\n",
        "\n",
        "### 3. Predict function ###\n",
        "\n",
        "# Create predict function\n",
        "def effnetb2_predict(img):\n",
        "    \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
        "    \"\"\"\n",
        "    # Start the timer\n",
        "    start_time = timer()\n",
        "    \n",
        "    # Transform the target image and add a batch dimension\n",
        "    img = effnetb2_transforms(img).unsqueeze(0)\n",
        "    \n",
        "    # Put model into evaluation mode and turn on inference mode\n",
        "    effnetb2.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
        "        pred_probs = torch.softmax(effnetb2(img), dim=1)\n",
        "    \n",
        "    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)\n",
        "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "    \n",
        "    # Calculate the prediction time\n",
        "    pred_time = round(timer() - start_time, 5)\n",
        "    \n",
        "    # Return the prediction dictionary and prediction time \n",
        "    return pred_labels_and_probs, pred_time\n",
        "\n",
        "### 4. Gradio app ###\n",
        "\n",
        "# Create title, description and article strings\n",
        "title = \"Food101 Big\"\n",
        "description = \"An EfficientNetB2 feature extractor computer vision model to classify images of food using whole Food101 dataset.\"\n",
        "article = \"Created at 07. PyTorch Model Deployment\"\n",
        "\n",
        "# Create the Gradio demo\n",
        "demo = gr.Interface(fn=effnetb2_predict, # mapping function from input to output\n",
        "                    inputs=gr.Image(type=\"pil\"), # what are the inputs?\n",
        "                    outputs=[gr.Label(num_top_classes=5, label=\"Predictions\"), # what are the outputs?\n",
        "                             gr.Number(label=\"Prediction time (s)\")], # our fn has two outputs, therefore we have two outputs\n",
        "                    examples=example_list, \n",
        "                    title=title,\n",
        "                    description=description,\n",
        "                    article=article)\n",
        "\n",
        "# Launch the demo!\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5ITtjszddQs"
      },
      "source": [
        "### 8.8 Creating a requirements file for FoodVision Big (`requirements.txt`)\n",
        "\n",
        "The last file we need to create for our FoodVision Big app is a `requirements.txt` file.\n",
        "\n",
        "This will be a text file containing all of the required dependencies for our demo.\n",
        "\n",
        "When we deploy our demo app to Hugging Face Spaces, it will search through this file and install the dependencies we define so our app can run.\n",
        "\n",
        "The good news is, there's only three!\n",
        "\n",
        "1. `torch`\n",
        "2. `torchvision`\n",
        "3. `gradio`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "goQBpRF0ddQs",
        "outputId": "81669562-7219-4005-ed21-3b6458d4bb6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/foodvision_big/requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile demos/foodvision_big/requirements.txt\n",
        "torch\n",
        "torchvision\n",
        "gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFT4js_lddQs"
      },
      "source": [
        "Nice!\n",
        "\n",
        "We've officially got all the files we need to deploy our FoodVision Big demo!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "0caky4LjddQs"
      },
      "source": [
        "## 9. Deploying our FoodVision Big app to HuggingFace Spaces\n",
        "\n",
        "There are two main options for uploading to a Hugging Face Space (also called a [Hugging Face Repository](https://huggingface.co/docs/hub/repositories-getting-started#getting-started-with-repositories), similar to a git repository): \n",
        "1. [Uploading via the Hugging Face Web interface (easiest)](https://huggingface.co/docs/hub/repositories-getting-started#adding-files-to-a-repository-web-ui).\n",
        "2. [Uploading via the command line or terminal](https://huggingface.co/docs/hub/repositories-getting-started#terminal).\n",
        "    * **Bonus:** You can also use the [`huggingface_hub` library](https://huggingface.co/docs/huggingface_hub/index) to interact with Hugging Face, this would be a good extension to the above two options.\n",
        "\n",
        "\n",
        "> **Note:** To host anything on Hugging Face, you will to [sign up for a free Hugging Face account](https://huggingface.co/join). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pBRSX9MddQt"
      },
      "source": [
        "### Downloading our FoodVision Big app files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Yt1_BW_6ddQu",
        "outputId": "427a6558-6c20-4167-ee7a-c6e287faaa9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\t\t food101_effnetb2_feature_extractor_101classes.pth\n",
            "class_names.txt  model.py\n",
            "examples\t requirements.txt\n"
          ]
        }
      ],
      "source": [
        "!ls demos/foodvision_big"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gnp_kSQddQu"
      },
      "source": [
        "These are all files that we've created!\n",
        "\n",
        "To begin uploading our files to Hugging Face, let's now download them from Google Colab (or wherever you're running this notebook).\n",
        "\n",
        "To do so, we'll first compress the files into a single zip folder via the command: \n",
        "\n",
        "```\n",
        "zip -r ../foodvision_big.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\"\n",
        "```\n",
        "\n",
        "Where: \n",
        "* `zip` stands for \"zip\" as in \"please zip together the files in the following directory\". \n",
        "* `-r` stands for \"recursive\" as in, \"go through all of the files in the target directory\".\n",
        "* `../foodvision_big.zip` is the target directory we'd like our files to be zipped to.\n",
        "* `*` stands for \"all the files in the current directory\".\n",
        "* `-x` stands for \"exclude these files\". \n",
        "\n",
        "We can download our zip file from Google Colab using [`google.colab.files.download(\"demos/foodvision_big.zip\")`](https://colab.research.google.com/notebooks/io.ipynb) (we'll put this inside a `try` and `except` block just in case we're not running the code inside Google Colab, and if so we'll print a message saying to manually download the files).\n",
        "\n",
        "Let's try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "tags": [],
        "id": "bIvxwi6mddQv",
        "outputId": "2ad0095f-c255-4fc7-a41d-49770bf0a8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: app.py (deflated 57%)\n",
            "  adding: class_names.txt (deflated 48%)\n",
            "  adding: examples/ (stored 0%)\n",
            "  adding: examples/124695.jpg (deflated 0%)\n",
            "  adding: examples/177513.jpg (deflated 0%)\n",
            "  adding: examples/1284428.jpg (deflated 1%)\n",
            "  adding: food101_effnetb2_feature_extractor_101classes.pth (deflated 8%)\n",
            "  adding: model.py (deflated 55%)\n",
            "  adding: requirements.txt (deflated 4%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85e707c2-e272-412c-982e-9cc1ae62c125\", \"foodvision_big.zip\", 29423117)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Zip foodvision_big folder but exclude certain files\n",
        "!cd demos/foodvision_big && zip -r ../foodvision_big.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\"\n",
        "\n",
        "# Download the zipped FoodVision Big app (if running in Google Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"demos/foodvision_big.zip\")\n",
        "except:\n",
        "    print(\"Not running in Google Colab, can't use google.colab.files.download()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "uFNOTzY0ddQy"
      },
      "source": [
        "### Running our FoodVision Big demo locally (optional)\n",
        "\n",
        "If you download the `foodvision_big.zip` file, you can test it locally by:\n",
        "1. Unzipping the file.\n",
        "2. Opening terminal or a command line prompt.\n",
        "3. Changing into the `foodvision_big` directory (`cd foodvision_big`).\n",
        "4. Creating an environment (`python3 -m venv env`).\n",
        "5. Activating the environment (`source env/bin/activate`).\n",
        "5. Installing the requirements (`pip install -r requirements.txt`, the \"`-r`\" is for recursive).\n",
        "    * **Note:** This step may take 5-10 minutes depending on your internet connection. And if you're facing errors, you may need to upgrade `pip` first: `pip install --upgrade pip`.\n",
        "6. Run the app (`python3 app.py`).\n",
        "\n",
        "This should result in a Gradio demo just like the one we built above.\n",
        "\n",
        "> **Note:** If you run the app locally and you notice a `flagged/` directory appear, it contains samples that have been \"flagged\". \n",
        ">\n",
        "> For example, if someone tries the demo and the model produces an incorrect result, the sample can be \"flagged\" and reviewed for later.\n",
        "> \n",
        "> For more on flagging in Gradio, see the [flagging documentation](https://gradio.app/docs/#flagging)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "74QllPDxddQ4"
      },
      "source": [
        "### Uploading to Hugging Face\n",
        "\n",
        "We've verfied our FoodVision Mini app works locally, however, the fun of creating a machine learning demo is to show it to other people and allow them to use it.\n",
        "\n",
        "To do so, we're going to upload our FoodVision Mini demo to Hugging Face. \n",
        "\n",
        "> **Note:** The following series of steps uses a Git (a file tracking system) workflow. For more on how Git works, I'd recommend going through the [Git and GitHub for Beginners tutorial](https://youtu.be/RGOj5yH7evk) on freeCodeCamp.\n",
        "\n",
        "1. [Sign up](https://huggingface.co/join) for a Hugging Face account. \n",
        "2. Start a new Hugging Face Space by going to your profile and then [clicking \"New Space\"](https://huggingface.co/new-space).\n",
        "    * **Note:** A Space in Hugging Face is also known as a \"code repository\" (a place to store your code/files) or \"repo\" for short.\n",
        "3. Give the Space a name\n",
        "4. Select a license (I used [MIT](https://opensource.org/licenses/MIT)).\n",
        "5. Select Gradio as the Space SDK (software development kit). \n",
        "   * **Note:** You can use other options such as Streamlit but since our app is built with Gradio, we'll stick with that.\n",
        "6. Choose whether your Space is it's public or private (we select public since we like our Space to be available to others).\n",
        "7. Click \"Create Space\".\n",
        "8. Clone the repo locally by running something like: `git clone https://huggingface.co/spaces/[YOUR_USERNAME]/[YOUR_SPACE_NAME]` in terminal or command prompt.\n",
        "    * **Note:** You can also add files via uploading them under the \"Files and versions\" tab.\n",
        "9. Copy/move the contents of the downloaded `foodvision_big` folder to the cloned repo folder.\n",
        "10. To upload and track larger files (e.g. files over 10MB or in our case, our PyTorch model file) you'll need to [install Git LFS](https://git-lfs.github.com/) (which stands for \"git large file storage\").\n",
        "11. After you've installed Git LFS, you can activate it by running `git lfs install`.\n",
        "12. In the `foodvision_big` directory, track the files over 10MB with Git LFS with `git lfs track \"*.file_extension\"`.\n",
        "    * Track EffNetB2 PyTorch model file with `git lfs track \"food101_effnetb2_feature_extractor_101classes.pth\"`.\n",
        "13. Track `.gitattributes` (automatically created when cloning from HuggingFace, this file will help ensure our larger files are tracked with Git LFS).\n",
        "    * `git add .gitattributes`\n",
        "14. Add the rest of the `foodvision_big` app files and commit them with: \n",
        "    * `git add *`\n",
        "    * `git commit -m \"first commit\"`\n",
        "15. Push (upload) the files to Hugging Face:\n",
        "    * `git push`\n",
        "16. Wait 3-5 minutes for the build to happen (future builds are faster) and your app to become live!\n",
        "\n",
        "\n",
        "And we can even embed our FoodVision Big Gradio demo into our notebook as an [iframe](https://gradio.app/sharing_your_app/#embedding-with-iframes) with [`IPython.display.IFrame`](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.IFrame) and a link to our space in the format `https://hf.space/embed/[YOUR_USERNAME]/[YOUR_SPACE_NAME]/+`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "LsJQZb5oddQ6",
        "outputId": "6abb270a-8601-4cd7-a829-d5bd92429798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f2b7e6d0090>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"750\"\n",
              "            src=\"https://hf.space/embed/VesalAhsani/FoodVisionBig_firstDraft/+\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# IPython is a library to help work with Python iteractively \n",
        "from IPython.display import IFrame\n",
        "\n",
        "# Embed FoodVision Big Gradio demo as an iFrame\n",
        "IFrame(src=\"https://hf.space/embed/VesalAhsani/FoodVisionBig_firstDraft/+\", width=900, height=750)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome ✌\n",
        "\n",
        "now we're building computer vision models accessible to people all around the world!"
      ],
      "metadata": {
        "id": "1tQiZ75NlayK"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Cr61DbaJddQn",
        "fwypu2HSddQn",
        "uFNOTzY0ddQy"
      ],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "709a6846dfcc492f8e47fb4ad6e457a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6e14a21e6424afaa3e386fde4255f4c",
              "IPY_MODEL_84ba9a44053340aabb89b8d90fbe6dec",
              "IPY_MODEL_8301450d882f4c0e9aa8239725c47152"
            ],
            "layout": "IPY_MODEL_8eb4b750b6154e74aeaa6d9a926a4356"
          }
        },
        "e6e14a21e6424afaa3e386fde4255f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19521d3676284c83818999591c4c66fd",
            "placeholder": "​",
            "style": "IPY_MODEL_1f89828c17a844b18a30ad75f023d2f8",
            "value": "100%"
          }
        },
        "84ba9a44053340aabb89b8d90fbe6dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5105a1bd374047ffa61b7ce6fded38b2",
            "max": 36882185,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3813be9fc8fb4f2ca191779b94a585dd",
            "value": 36882185
          }
        },
        "8301450d882f4c0e9aa8239725c47152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ae5c80aa954ee7a6ec96bace12cb27",
            "placeholder": "​",
            "style": "IPY_MODEL_77bcc2babd4e4f94b873b6e6a5b2a665",
            "value": " 35.2M/35.2M [00:00&lt;00:00, 71.4MB/s]"
          }
        },
        "8eb4b750b6154e74aeaa6d9a926a4356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19521d3676284c83818999591c4c66fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f89828c17a844b18a30ad75f023d2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5105a1bd374047ffa61b7ce6fded38b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3813be9fc8fb4f2ca191779b94a585dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4ae5c80aa954ee7a6ec96bace12cb27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77bcc2babd4e4f94b873b6e6a5b2a665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d7baeb96d934c3f9a947537e224b006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc6c141309bf40ac8b994eb00781a4a3",
              "IPY_MODEL_8a674293a66046159e78bf0dfeb138a9",
              "IPY_MODEL_0168096c8119457697f756a00ec2b669"
            ],
            "layout": "IPY_MODEL_2bcf3272802d46baa3d40a224cd317c6"
          }
        },
        "fc6c141309bf40ac8b994eb00781a4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c521c54541ea463a8d9363a87b4a012e",
            "placeholder": "​",
            "style": "IPY_MODEL_c784a3ae3f1740b0871701dc6478ddde",
            "value": "100%"
          }
        },
        "8a674293a66046159e78bf0dfeb138a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_426e49392cb8494cba238a2bd1cf2db3",
            "max": 4996278331,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98a0fd8fecdf4d93af7da41b9e171b4b",
            "value": 4996278331
          }
        },
        "0168096c8119457697f756a00ec2b669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f25fa5392c1442f08f4c8d544c1ff0d6",
            "placeholder": "​",
            "style": "IPY_MODEL_db3b5ae008324de08e365ef8f3b73c2a",
            "value": " 4996278331/4996278331 [04:31&lt;00:00, 18417216.45it/s]"
          }
        },
        "2bcf3272802d46baa3d40a224cd317c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c521c54541ea463a8d9363a87b4a012e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c784a3ae3f1740b0871701dc6478ddde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "426e49392cb8494cba238a2bd1cf2db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a0fd8fecdf4d93af7da41b9e171b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f25fa5392c1442f08f4c8d544c1ff0d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db3b5ae008324de08e365ef8f3b73c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c441a6838b7a4185b9d55c8066b816dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34d1c78ffd344d4781ad3009b20c41a1",
              "IPY_MODEL_b53978f8b5cb4b58828b208441b7cf0c",
              "IPY_MODEL_650a82d2f6d74c66b2de76bda1cd7123"
            ],
            "layout": "IPY_MODEL_b3b127c2680a4f9396710790dd6d559d"
          }
        },
        "34d1c78ffd344d4781ad3009b20c41a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28682488e055400ebceda82ad4f554ac",
            "placeholder": "​",
            "style": "IPY_MODEL_55941e543f244ceaa693f9b687a49982",
            "value": "100%"
          }
        },
        "b53978f8b5cb4b58828b208441b7cf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_445b389bb1604f16b595250eea30d18e",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66be4353933448a689cb6c6ca4b201d0",
            "value": 5
          }
        },
        "650a82d2f6d74c66b2de76bda1cd7123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b5c84c25034c9f8ed5289bad4832f4",
            "placeholder": "​",
            "style": "IPY_MODEL_b200aa5facfc4bcc97ca2c7f492382b2",
            "value": " 5/5 [2:00:32&lt;00:00, 1439.82s/it]"
          }
        },
        "b3b127c2680a4f9396710790dd6d559d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28682488e055400ebceda82ad4f554ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55941e543f244ceaa693f9b687a49982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "445b389bb1604f16b595250eea30d18e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66be4353933448a689cb6c6ca4b201d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4b5c84c25034c9f8ed5289bad4832f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b200aa5facfc4bcc97ca2c7f492382b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d54ca77e79814bc0b0af4add34e6935f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cf52d09b0124f76914329b3bba500ac",
              "IPY_MODEL_61865f4b8f164c589739107233174511",
              "IPY_MODEL_d8705e6fd7db47469cbc2c8d34526626"
            ],
            "layout": "IPY_MODEL_96cc08dcf8a24da3aaf63195b38719be"
          }
        },
        "4cf52d09b0124f76914329b3bba500ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ad90fbb2fc44b9b13f7ac2a8e994c1",
            "placeholder": "​",
            "style": "IPY_MODEL_b07193691d0d4f72bcaede756cb39606",
            "value": "100%"
          }
        },
        "61865f4b8f164c589739107233174511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f02d1012c040658d028a4f14b4a663",
            "max": 346328529,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0ffd6e023614e6ca059f884b36b93b4",
            "value": 346328529
          }
        },
        "d8705e6fd7db47469cbc2c8d34526626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acaf74a523e14d1cb584c42da06e493a",
            "placeholder": "​",
            "style": "IPY_MODEL_3d12afe59ef443df8094eecae1e830e4",
            "value": " 330M/330M [00:02&lt;00:00, 127MB/s]"
          }
        },
        "96cc08dcf8a24da3aaf63195b38719be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ad90fbb2fc44b9b13f7ac2a8e994c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b07193691d0d4f72bcaede756cb39606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44f02d1012c040658d028a4f14b4a663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ffd6e023614e6ca059f884b36b93b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acaf74a523e14d1cb584c42da06e493a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d12afe59ef443df8094eecae1e830e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bf36dee0b5e4a588d0e314bb1a337c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47e4ee23a22e42e994dbbe783af597b5",
              "IPY_MODEL_38206fa1261742f59f9f9d6b1d88e25d",
              "IPY_MODEL_6014d705a4ff49169bddb7559c43aa44"
            ],
            "layout": "IPY_MODEL_b975c407a29541038684e3be84df00e7"
          }
        },
        "47e4ee23a22e42e994dbbe783af597b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5930e5570a844e4877153048754d3de",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1ba6f47b43487297f484d131f593a6",
            "value": "100%"
          }
        },
        "38206fa1261742f59f9f9d6b1d88e25d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94a2164e9f814296ab1f7060e024b38c",
            "max": 4996278331,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe845a6a86814fad9f6816c512d08524",
            "value": 4996278331
          }
        },
        "6014d705a4ff49169bddb7559c43aa44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_534af872b3424105a4dc9dae31beb024",
            "placeholder": "​",
            "style": "IPY_MODEL_152bffe848d6451b8a482e353e60c9c1",
            "value": " 4996278331/4996278331 [05:44&lt;00:00, 15819867.10it/s]"
          }
        },
        "b975c407a29541038684e3be84df00e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5930e5570a844e4877153048754d3de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1ba6f47b43487297f484d131f593a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94a2164e9f814296ab1f7060e024b38c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe845a6a86814fad9f6816c512d08524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "534af872b3424105a4dc9dae31beb024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "152bffe848d6451b8a482e353e60c9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e1ddd75210842b1b6032a00cb72346b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcd36c20f78743f9b1562c52dac39390",
              "IPY_MODEL_28f7c2429aef42659f9442a36e90c0c4",
              "IPY_MODEL_b38afa012245408da9661553425f72e6"
            ],
            "layout": "IPY_MODEL_a01018e9acd2483f9d8cbcea73975615"
          }
        },
        "fcd36c20f78743f9b1562c52dac39390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5681c20c54416fb76381723b26d580",
            "placeholder": "​",
            "style": "IPY_MODEL_b6a1b8cc99d043b9a9ac3d2fdaebc767",
            "value": "100%"
          }
        },
        "28f7c2429aef42659f9442a36e90c0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16df436943fb45c4abd5ea0294671d8b",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba06548912f749b894617a8452461645",
            "value": 5
          }
        },
        "b38afa012245408da9661553425f72e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_894e4910bc6b4b9fa8574bddde5e21a2",
            "placeholder": "​",
            "style": "IPY_MODEL_3a63fa36523b492cb91423220f398f0f",
            "value": " 5/5 [1:43:13&lt;00:00, 1239.33s/it]"
          }
        },
        "a01018e9acd2483f9d8cbcea73975615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5681c20c54416fb76381723b26d580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a1b8cc99d043b9a9ac3d2fdaebc767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16df436943fb45c4abd5ea0294671d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba06548912f749b894617a8452461645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "894e4910bc6b4b9fa8574bddde5e21a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a63fa36523b492cb91423220f398f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30a7dc195e04f05acfed9971f363f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c69670fa60a64e0b9c04b2934f68bdbb",
              "IPY_MODEL_2778d721292540b8b0d89b1079d3bf8f",
              "IPY_MODEL_5512f36509eb43799cdabc7a70668a10"
            ],
            "layout": "IPY_MODEL_516c2567532c47bb9725df0be0d6c442"
          }
        },
        "c69670fa60a64e0b9c04b2934f68bdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808dac78e6124168a95209d03c8cc4bb",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0d2833059b453ba02e147dc14c2385",
            "value": "100%"
          }
        },
        "2778d721292540b8b0d89b1079d3bf8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f0f9eefbedb429caaa4d565639155ca",
            "max": 5050,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ccc2510b9fa4db2886fc07545397b9b",
            "value": 5050
          }
        },
        "5512f36509eb43799cdabc7a70668a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2268a23b9f564b129278071d938a25da",
            "placeholder": "​",
            "style": "IPY_MODEL_66c5e963ff734ad1a2cdaf671778290e",
            "value": " 5050/5050 [15:15&lt;00:00,  5.85it/s]"
          }
        },
        "516c2567532c47bb9725df0be0d6c442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808dac78e6124168a95209d03c8cc4bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0d2833059b453ba02e147dc14c2385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f0f9eefbedb429caaa4d565639155ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ccc2510b9fa4db2886fc07545397b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2268a23b9f564b129278071d938a25da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c5e963ff734ad1a2cdaf671778290e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1443be3a38f4d36a40d92d956e92678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8732ef3848fa4ccea4d62fbd10aff94a",
              "IPY_MODEL_8cb07ea8ee4b497eb62c8242a5dfb4e8",
              "IPY_MODEL_6355c09d17e04811aafbf6764bddbc66"
            ],
            "layout": "IPY_MODEL_a754e72a66024771a801fba13d05a340"
          }
        },
        "8732ef3848fa4ccea4d62fbd10aff94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_094ce8bfdb284a81a37f23ddee64176b",
            "placeholder": "​",
            "style": "IPY_MODEL_3888a252ce0148509c1a4d2ebfdcf18c",
            "value": "100%"
          }
        },
        "8cb07ea8ee4b497eb62c8242a5dfb4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_692e58c53b194bc683f6fb5bdd7d6e5d",
            "max": 5050,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35fe2554182f4ff1bbbb43891dcc99be",
            "value": 5050
          }
        },
        "6355c09d17e04811aafbf6764bddbc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e8966e1b2374f059c1287952f60a6cc",
            "placeholder": "​",
            "style": "IPY_MODEL_e280ee8b7aba4abb996eb470c9653cf0",
            "value": " 5050/5050 [01:57&lt;00:00, 43.69it/s]"
          }
        },
        "a754e72a66024771a801fba13d05a340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094ce8bfdb284a81a37f23ddee64176b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3888a252ce0148509c1a4d2ebfdcf18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "692e58c53b194bc683f6fb5bdd7d6e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35fe2554182f4ff1bbbb43891dcc99be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e8966e1b2374f059c1287952f60a6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e280ee8b7aba4abb996eb470c9653cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}